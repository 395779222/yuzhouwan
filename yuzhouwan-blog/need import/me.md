#__联系方式__
* &nbsp;手机:&nbsp;181-151-87339
* &nbsp;Email:&nbsp;jinjiayi_1993@outlook.com
* &nbsp;QQ:&nbsp;1571805553

---

#__个人信息__
* &nbsp;金嘉怡/男/1993
* &nbsp;本科/南京工程学院 - 康尼学院 - 计算机科学与技术
* &nbsp;1年
* &nbsp;个人博客 : [www.yuzhouwan.com][1]
* &nbsp;CSDN : [oasiduofu][2]
* &nbsp;Github : [asdf2014][3]

---

#__工作经历__
###天诚逍逸 (2014 年 4 月 27 号  ~ 2014 年 6 月 20 号)<br>
&nbsp;&nbsp;&nbsp;&nbsp;参与校企合作的网络公司。在核心组，由从事 Hadoop 的公司技术员工[带队指导][4]。<br>

&nbsp;&nbsp;&nbsp;&nbsp;在 Linux 上搭建过 Hadoop2、Hive、Hbase、Strom、Sqoop  集群，并用其实现过一些简单的数据分析。<br>
&nbsp;&nbsp;&nbsp;&nbsp;1. flume 完成数据的采集<br>
&nbsp;&nbsp;&nbsp;&nbsp;2. 对数据进行清洗<br>
&nbsp;&nbsp;&nbsp;&nbsp;3. 使用 hive 进行数据的多维分析<br>
&nbsp;&nbsp;&nbsp;&nbsp;4. 把 hive 分析结果通过 sqoop 导入到 mysql 中，完成数据迁移<br>
&nbsp;&nbsp;&nbsp;&nbsp;5. 提供视图工具，供用户使用<br>
<br><br>


###南京贝特威信息技术有限公司(2014 年 7 月 10 号 ~ 2014 年 10 月 10 号)<br>
&nbsp;&nbsp;&nbsp;&nbsp;主要工作是 东方航空公司 的燃油税费系统的研发。<br>

&nbsp;&nbsp;&nbsp;&nbsp;涉及到的技术： <br>
&nbsp;&nbsp;&nbsp;&nbsp;Oracle & Access(PL/SQL) + MyBatis + Spring3 + Struts2 + JSP + EasyUI + WebService。<br>
&nbsp;&nbsp;&nbsp;&nbsp;根据东航税费项目专家组提供的 Specification 英文规范文档，完成对 Access 数据库的解析（在 Spring 中配置定时器 自动完成），并将数据导入到 Oracle 中，实现数据的迁移。<br>
&nbsp;&nbsp;&nbsp;&nbsp;并使用 EasyUI 将迁移的实时情况，展现在 web 浏览器中。<br>
&nbsp;&nbsp;&nbsp;&nbsp;同时，需要将迁移中生成的 bean 做成 excel 展示记录表，并将这部分工作总结抽象成更加全能的一个 [Beans2ExcelWithSheets][5] 工具 jar 包。<br>

---

#__技能清单__

###熟悉：
+ &nbsp;[Java][7]
+ &nbsp;[Hadoop][11] / Storm / [Spark][12] (Scala / Python)
+ &nbsp;[Node][8] (Connect, Express4.x, Hexo)
+ &nbsp;Spring (MVC, Shiro)
+ &nbsp;[Git][9]
+ &nbsp;JVM
+ &nbsp;SQL (MySQL/PostgreSQL)
+ &nbsp;NoSQL (MongoDB/HBase)

###了解：
+ &nbsp;iBatis
+ &nbsp;OSGi
+ &nbsp;[R][4]
+ &nbsp;Ruby
+ &nbsp;[Clojure][10]
+ &nbsp;UI
+ &nbsp;WebService
+ &nbsp;Struts
+ &nbsp;DBCP
+ &nbsp;JNI
+ &nbsp;Html5/EasyUI/JQuery(Ajax)

###大数据：

&nbsp;&nbsp;&nbsp;&nbsp;了解实时分析系统 Strom，内存计算框架 Spark (熟练掌握 Scala 编程)，数据流框架 Oozie 

&nbsp;&nbsp;&nbsp;&nbsp;熟悉 Shell 命令，熟练掌握 Crontab 的自动化脚本编程

&nbsp;&nbsp;&nbsp;&nbsp;能够使用 flume 实现数据的实时采集工作，并运用 Hive 对采集回来的数据，进行清洗、分析。同时，能够结合 flume 进 Hadoop 分布式文件系统的数据，关联其外部分区表 

&nbsp;&nbsp;&nbsp;&nbsp;脱离 derby 的存储方式，使用 MySQL 对 meatstore 进行保存，实现了多用户并发操作 Hive 

&nbsp;&nbsp;&nbsp;&nbsp;熟练掌握 HBase，了解面向列型数据库的存储机制 

&nbsp;&nbsp;&nbsp;&nbsp;能熟练使用 sqoop，利用其实现 关系型数据库 与 HBase 之间的数据迁移

&nbsp;&nbsp;&nbsp;&nbsp;知晓 ZooKeeper 的 HA 实现方式 

&nbsp;&nbsp;&nbsp;&nbsp;了解 HDFS 运作机制，能在 yarn 上熟练编写 MapReducer，并能够通过 Combiner 均衡 Reducer 主机的压力，以及 Partitioner 将结果集写入到不同的 hdfs 文件中 

&nbsp;&nbsp;&nbsp;&nbsp;熟悉 Hadoop 的生态圈，研读过 RPC 部分源码 


---

#__致谢__
感谢您花时间阅读我的简历，期待能有机会和您共事。

在线简历 : [https://github.com/asdf2014/asdf2014.github.io/blob/master/me.md][6]


[1]:http://www.yuzhouwan.com
[2]:http://blog.csdn.net/oasiduofu
[3]:http://github.com/asdf2014
[4]:https://github.com/MasteringR/R
[5]:http://blog.csdn.net/oasiduofu/article/details/38550367
[6]:https://github.com/asdf2014/asdf2014.github.io/blob/master/me.md
[7]:https://github.com/MasteringJava
[8]:https://github.com/NodeJSAction
[9]:https://github.com/asdf2014/
[10]:https://github.com/MasteringClojure
[11]:https://github.com/MasteringHadoop
[12]:https://github.com/MasteringHadoop/Scala
