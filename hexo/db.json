{"Asset":[{"_id":"source\\favicon.ico","path":"favicon.ico","modified":false},{"_id":"source\\2014-11-15\\session.png","path":"2014-11-15/session.png","modified":false},{"_id":"source\\2014-11-16\\DFS.getHomeDirectory.png","path":"2014-11-16/DFS.getHomeDirectory.png","modified":false},{"_id":"source\\2014-11-16\\DFS-is-ok!!!.png","path":"2014-11-16/DFS-is-ok!!!.png","modified":false},{"_id":"source\\2014-11-16\\DFS.open(f,bufferSize).png","path":"2014-11-16/DFS.open(f,bufferSize).png","modified":false},{"_id":"source\\2014-11-16\\DFS.initialize.png","path":"2014-11-16/DFS.initialize.png","modified":false},{"_id":"source\\2014-11-16\\DFSClient(nameNodeUri,rpcNamenode,conf,stats).png","path":"2014-11-16/DFSClient(nameNodeUri,rpcNamenode,conf,stats).png","modified":false},{"_id":"source\\2014-11-16\\DFSClient.png","path":"2014-11-16/DFSClient.png","modified":false},{"_id":"source\\2014-11-16\\DistributedFileSystem.png","path":"2014-11-16/DistributedFileSystem.png","modified":false},{"_id":"source\\2014-11-16\\FSDataInputStream--open(path).png","path":"2014-11-16/FSDataInputStream--open(path).png","modified":false},{"_id":"source\\2014-11-16\\FileOutputStream.png","path":"2014-11-16/FileOutputStream.png","modified":false},{"_id":"source\\2014-11-16\\FileSystem.get(uri,conf,user).png","path":"2014-11-16/FileSystem.get(uri,conf,user).png","modified":false},{"_id":"source\\2014-11-16\\FileSystem.png","path":"2014-11-16/FileSystem.png","modified":false},{"_id":"source\\2014-11-16\\FileSystems.png","path":"2014-11-16/FileSystems.png","modified":false},{"_id":"source\\2014-11-16\\HdfsDataInputStream.png","path":"2014-11-16/HdfsDataInputStream.png","modified":false},{"_id":"source\\2014-11-16\\IOUtiles.copyBytes(in,out,buffSize).png","path":"2014-11-16/IOUtiles.copyBytes(in,out,buffSize).png","modified":false},{"_id":"source\\2014-11-16\\Path.png","path":"2014-11-16/Path.png","modified":false},{"_id":"source\\2014-11-16\\Proxy.png","path":"2014-11-16/Proxy.png","modified":false},{"_id":"source\\2014-11-16\\RPC-success.png","path":"2014-11-16/RPC-success.png","modified":false},{"_id":"source\\2014-11-16\\ReflectionUtils.newInstance--DFS.png","path":"2014-11-16/ReflectionUtils.newInstance--DFS.png","modified":false},{"_id":"source\\2014-11-16\\URI.create.png","path":"2014-11-16/URI.create.png","modified":false},{"_id":"source\\2014-11-16\\hdfs.png","path":"2014-11-16/hdfs.png","modified":false},{"_id":"source\\2014-11-16\\buffSize.png","path":"2014-11-16/buffSize.png","modified":false},{"_id":"source\\2014-11-16\\host-yuzhouwan.png","path":"2014-11-16/host-yuzhouwan.png","modified":false},{"_id":"source\\2015-2-2\\say-hello.png","path":"2015-2-2/say-hello.png","modified":false},{"_id":"source\\2014-11-5\\steps-to-finding-a-main-file.png","path":"2014-11-5/steps-to-finding-a-main-file.png","modified":false},{"_id":"source\\2014-11-5\\steps-to-finding-a-module.png","path":"2014-11-5/steps-to-finding-a-module.png","modified":false},{"_id":"source\\2015-5-10\\kafka.png","path":"2015-5-10/kafka.png","modified":false},{"_id":"source\\logos\\Year_2038_problem.gif","path":"logos/Year_2038_problem.gif","modified":false},{"_id":"source\\logos\\it_cast.png","path":"logos/it_cast.png","modified":false},{"_id":"source\\logos\\it_ebooks.png","path":"logos/it_ebooks.png","modified":false},{"_id":"source\\logos\\safari.png","path":"logos/safari.png","modified":false},{"_id":"themes\\light\\source\\fancybox\\fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":false},{"_id":"themes\\light\\source\\fancybox\\fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":false},{"_id":"themes\\light\\source\\fancybox\\blank.gif","path":"fancybox/blank.gif","modified":false},{"_id":"themes\\light\\source\\fancybox\\fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":false},{"_id":"themes\\light\\source\\fancybox\\fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":false},{"_id":"themes\\light\\source\\fancybox\\fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":false},{"_id":"themes\\light\\source\\fancybox\\jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":false},{"_id":"themes\\light\\source\\fancybox\\jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":false},{"_id":"themes\\light\\source\\js\\gallery.js","path":"js/gallery.js","modified":false},{"_id":"themes\\light\\source\\js\\jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":false},{"_id":"themes\\light\\source\\css\\style.styl","path":"css/style.styl","modified":false},{"_id":"themes\\light\\source\\css\\font\\fontawesome-webfont.svg","path":"css/font/fontawesome-webfont.svg","modified":false},{"_id":"themes\\light\\source\\css\\font\\fontawesome-webfont.eot","path":"css/font/fontawesome-webfont.eot","modified":false},{"_id":"themes\\light\\source\\css\\font\\fontawesome-webfont.ttf","path":"css/font/fontawesome-webfont.ttf","modified":false},{"_id":"themes\\light\\source\\css\\font\\fontawesome-webfont.woff","path":"css/font/fontawesome-webfont.woff","modified":false},{"_id":"source\\logos\\packtpub.png","path":"logos/packtpub.png","modified":false},{"_id":"source\\logos\\google.png","path":"logos/google.png","modified":false},{"_id":"source\\logos\\salttiger.png","path":"logos/salttiger.png","modified":false},{"_id":"source\\logos\\hejizhan.png","path":"logos/hejizhan.png","modified":false},{"_id":"source\\2015-8-13\\Spark.png","path":"2015-8-13/Spark.png","modified":false},{"_id":"source\\2015-8-13\\storm.jpg","path":"2015-8-13/storm.jpg","modified":false}],"Cache":[{"_id":"scaffolds\\draft.md","mtime":1416108978000},{"_id":"scaffolds\\page.md","mtime":1416108978000},{"_id":"scaffolds\\photo.md","mtime":1416108978000},{"_id":"scaffolds\\post.md","mtime":1416130718000},{"_id":"source\\favicon.ico","mtime":1414901370000},{"_id":"source\\2014-11-15\\session.png","mtime":1416037173000},{"_id":"source\\2014-11-16\\DFS.getHomeDirectory.png","mtime":1416131107000},{"_id":"source\\2014-11-16\\DFS-is-ok!!!.png","mtime":1416131184000},{"_id":"source\\2014-11-16\\DFS.open(f,bufferSize).png","mtime":1416131332000},{"_id":"source\\2014-11-16\\DFS.initialize.png","mtime":1416130694000},{"_id":"source\\2014-11-16\\DFSClient(nameNodeUri,rpcNamenode,conf,stats).png","mtime":1416130927000},{"_id":"source\\2014-11-16\\DFSClient.png","mtime":1416130772000},{"_id":"source\\2014-11-16\\DistributedFileSystem.png","mtime":1416131907000},{"_id":"source\\2014-11-16\\FSDataInputStream--open(path).png","mtime":1416131956000},{"_id":"source\\2014-11-16\\FileOutputStream.png","mtime":1416131484000},{"_id":"source\\2014-11-16\\FileSystem.get(uri,conf,user).png","mtime":1416131140000},{"_id":"source\\2014-11-16\\FileSystem.png","mtime":1416130931000},{"_id":"source\\2014-11-16\\FileSystems.png","mtime":1416129112000},{"_id":"source\\2014-11-16\\HdfsDataInputStream.png","mtime":1416131463000},{"_id":"source\\2014-11-16\\IOUtiles.copyBytes(in,out,buffSize).png","mtime":1416131598000},{"_id":"source\\2014-11-16\\Path.png","mtime":1416132140000},{"_id":"source\\2014-11-16\\Proxy.png","mtime":1416130831000},{"_id":"source\\2014-11-16\\RPC-success.png","mtime":1416131646000},{"_id":"source\\2014-11-16\\ReflectionUtils.newInstance--DFS.png","mtime":1416130153000},{"_id":"source\\2014-11-16\\URI.create.png","mtime":1416131021000},{"_id":"source\\2014-11-16\\hdfs.png","mtime":1416131419000},{"_id":"source\\2014-11-16\\buffSize.png","mtime":1416131499000},{"_id":"source\\2014-11-16\\host-yuzhouwan.png","mtime":1416131590000},{"_id":"source\\2015-2-2\\say-hello.png","mtime":1420974706000},{"_id":"source\\2014-11-5\\steps-to-finding-a-main-file.png","mtime":1415148803000},{"_id":"source\\2014-11-5\\steps-to-finding-a-module.png","mtime":1415148660000},{"_id":"source\\2015-5-10\\kafka.png","mtime":1431237380000},{"_id":"source\\_posts\\Antlr4.md","mtime":1420973871000},{"_id":"source\\_posts\\DIRT.md","mtime":1415065386000},{"_id":"source\\_posts\\Hadoop-RPC-源码领略.md","mtime":1416129808000},{"_id":"source\\_posts\\Node-模块.md","mtime":1416131502000},{"_id":"source\\_posts\\Python-Libraries.md","mtime":1423233648000},{"_id":"source\\_posts\\Qcon-2015-见闻之一：猿题库.md","mtime":1429978624000},{"_id":"source\\_posts\\SSO.md","mtime":1416131117000},{"_id":"source\\_posts\\Session.md","mtime":1416131455000},{"_id":"source\\_posts\\Storm-与-Kafka-的整合之三：Combination.md","mtime":1431245174000},{"_id":"source\\_posts\\Storm-与-Kafka-的整合之一：Storm.md","mtime":1429872749000},{"_id":"source\\_posts\\Storm-与-Kafka-的整合之二：Kafka.md","mtime":1439456683000},{"_id":"source\\_posts\\What-is-the-Node-js.md","mtime":1414997690000},{"_id":"source\\_posts\\asdf-s-Hexo-Blog.md","mtime":1416129181000},{"_id":"source\\_posts\\为什么-JavaScript-对服务端开发很重要.md","mtime":1416130474000},{"_id":"source\\_posts\\散列表.md","mtime":1416130772000},{"_id":"source\\_posts\\海纳百川.md","mtime":1439456615000},{"_id":"source\\_posts\\debug.log","mtime":1420973776000},{"_id":"source\\logos\\Year_2038_problem.gif","mtime":1436526912000},{"_id":"source\\logos\\it_cast.png","mtime":1439359304000},{"_id":"source\\logos\\it_ebooks.png","mtime":1436527258000},{"_id":"source\\logos\\safari.png","mtime":1436527031000},{"_id":"themes\\light\\_config.yml","mtime":1414900325000},{"_id":"themes\\light\\LICENSE","mtime":1414805031000},{"_id":"themes\\light\\README.md","mtime":1414805031000},{"_id":"themes\\light\\debug.log","mtime":1414994998000},{"_id":"themes\\light\\languages\\de.yml","mtime":1414805031000},{"_id":"themes\\light\\languages\\default.yml","mtime":1414805031000},{"_id":"themes\\light\\languages\\es.yml","mtime":1414805031000},{"_id":"themes\\light\\languages\\ru.yml","mtime":1414805031000},{"_id":"themes\\light\\languages\\zh-CN.yml","mtime":1414805031000},{"_id":"themes\\light\\languages\\zh-TW.yml","mtime":1414805031000},{"_id":"themes\\light\\layout\\archive.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\index.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\category.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\layout.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\page.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\post.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\tag.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_widget\\blogroll.ejs","mtime":1439434780000},{"_id":"themes\\light\\layout\\_widget\\category.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_widget\\search.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_widget\\recent_posts.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_widget\\tag.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_widget\\tagcloud.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\after_footer.ejs","mtime":1414824447000},{"_id":"themes\\light\\layout\\_partial\\archive.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\article.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\comment.ejs","mtime":1416108676000},{"_id":"themes\\light\\layout\\_partial\\debug.log","mtime":1416104078000},{"_id":"themes\\light\\layout\\_partial\\footer.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\facebook_comment.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\google_analytics.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\header.ejs","mtime":1414825046000},{"_id":"themes\\light\\layout\\_partial\\head.ejs","mtime":1414898012000},{"_id":"themes\\light\\layout\\_partial\\pagination.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\sidebar.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\post\\share.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\post\\gallery.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\post\\category.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\post\\tag.ejs","mtime":1414805031000},{"_id":"themes\\light\\layout\\_partial\\post\\title.ejs","mtime":1414805031000},{"_id":"themes\\light\\source\\fancybox\\fancybox_loading.gif","mtime":1414805031000},{"_id":"themes\\light\\source\\fancybox\\fancybox_loading@2x.gif","mtime":1414805031000},{"_id":"themes\\light\\source\\fancybox\\blank.gif","mtime":1414805031000},{"_id":"themes\\light\\source\\fancybox\\fancybox_overlay.png","mtime":1414805031000},{"_id":"themes\\light\\source\\fancybox\\fancybox_sprite.png","mtime":1414805031000},{"_id":"themes\\light\\source\\fancybox\\fancybox_sprite@2x.png","mtime":1414805031000},{"_id":"themes\\light\\source\\fancybox\\jquery.fancybox.css","mtime":1414805031000},{"_id":"themes\\light\\source\\fancybox\\jquery.fancybox.pack.js","mtime":1414805031000},{"_id":"themes\\light\\source\\js\\gallery.js","mtime":1414805031000},{"_id":"themes\\light\\source\\js\\jquery.imagesloaded.min.js","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\style.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_base\\layout.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_base\\variable.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_base\\utils.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_partial\\archive.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_partial\\article.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_partial\\comment.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_partial\\footer.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_partial\\header.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_partial\\index.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_partial\\sidebar.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\_partial\\syntax.styl","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\font\\fontawesome-webfont.svg","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\font\\fontawesome-webfont.eot","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\font\\fontawesome-webfont.ttf","mtime":1414805031000},{"_id":"themes\\light\\source\\css\\font\\fontawesome-webfont.woff","mtime":1414805031000},{"_id":"source\\logos\\packtpub.png","mtime":1436526658000},{"_id":"source\\logos\\google.png","mtime":1437633400000},{"_id":"source\\logos\\salttiger.png","mtime":1437755084000},{"_id":"source\\logos\\hejizhan.png","mtime":1438660054000},{"_id":"source\\2015-8-13\\Spark.png","mtime":1439356381000},{"_id":"source\\_posts\\Real-time-ML-with-Spark.md","mtime":1439531365000},{"_id":"source\\2015-8-13\\storm.jpg","mtime":1439449628000}],"Category":[{"name":"Hadoop","_id":"d06vmc3780sale4v","posts":["k67davxhfm4cdjf9"]},{"name":"RPC","parent":"d06vmc3780sale4v","_id":"tfcz81kys16gcygq","posts":["k67davxhfm4cdjf9"]},{"name":"Node.js","_id":"ifi2x4menzkubm48","posts":["v5tsu8wyv17axfu8","s9x4sgxklpdb0w6t","2jri9d9jo6z7stv1"]},{"name":"Module","parent":"ifi2x4menzkubm48","_id":"42j79qbe5jz59ye4","posts":["v5tsu8wyv17axfu8"]},{"name":"Python","_id":"80hi5d71gh1mfgtr","posts":["8asqaq0ueugeyyol"]},{"name":"Qcon","_id":"j75ue2n8rvuhvu7u","posts":["iddp8bje6jh1iem0"]},{"name":"SSO","_id":"62jx5vbvtw96qrcg","posts":["olrtd7b14rhsopss"]},{"name":"Session","_id":"x8unynvslphmme81","posts":["e62ebblg305ndghv"]},{"name":"Storm","_id":"k8prskk4oioqqy4b","posts":["keg97xozltugcohs","9zrz1hse4e1drwhv"]},{"name":"Kafka","parent":"k8prskk4oioqqy4b","_id":"68a0veepaufante1","posts":["keg97xozltugcohs"]},{"name":"Kafka","_id":"v7znvkc3c0heesni","posts":["lz5zae3p0ex7sg0i"]},{"name":"Hexo","_id":"yr9q5watou0iljwm","posts":["3ngs3hwwgl0vbull"]},{"name":"JavaScript","_id":"yv4bf02ij6h9d5lx","posts":["lzq1z1qvh0t5lofq"]},{"name":"HashMap","_id":"tsa5gxf1bo63eiuj","posts":["8d8a2twu1xotrk7c"]},{"name":"ConcurrentHashMap","parent":"tsa5gxf1bo63eiuj","_id":"ka9ae04rqkmpo6yw","posts":["8d8a2twu1xotrk7c"]},{"name":"Year_2038_problem","_id":"otry90hevjbvt7xb","posts":["3cdgmchgzaj82c9h"]},{"name":"Antlr","_id":"c4sd4umtpej6g9hp","posts":["rmw8s9n3g5m99v69"]},{"name":"Spark","_id":"w8x7zc0mnzcw36k5","posts":["fhowbkkc6xchvbmo"]}],"Page":[],"Post":[{"title":"Hadoop RPC 源码领略","date":1416132184000,"tags":["a1l3pj63cwx79a5o","3n9vfu5rcnuremwq"],"categories":["d06vmc3780sale4v","tfcz81kys16gcygq"],"content":"<h2 id=\"什么是_RPC_?\"><strong>什么是 RPC ?</strong></h2>\n<p>&nbsp;&nbsp; <font size=\"3\"> RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。 - - <a href=\"http://baike.baidu.com/item/%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8%E5%8D%8F%E8%AE%AE?fromtitle=RPC&amp;fr=aladdin\" target=\"_blank\" rel=\"external\">百度百科</a><br>&nbsp;&nbsp; <font size=\"3\"> 远程过程调用（Remote Procedure Call）是一种常用的分布式网络通讯协议，它允许运行于一台计算机的程序调用另一台计算机的子程序，同时将网络的通信细节隐藏起来，使得用户无需额外地外这个交互作用编程。 - - <a href=\"http://dongxicheng.org/\" target=\"_blank\" rel=\"external\">董的博客</a></font></font></p>\n<h2 id=\"为什么要有_RPC_?\"><strong>为什么要有 RPC ?</strong></h2>\n<h3 id=\"地域性：\"><strong>地域性</strong>：</h3>\n<p>&nbsp;&nbsp; <font size=\"3\"> 当主机不可达时，通过远程调用可以使得终端操作目标机器成为可能。</font></p>\n<h3 id=\"含糖性：\"><strong>含糖性</strong>：</h3>\n<p>&nbsp;&nbsp; <font size=\"3\"> 底层的网络通信细节封装入 API，方便网络分布式系统的开发。</font></p>\n<h3 id=\"模块化：\"><strong>模块化</strong>：</h3>\n<p>&nbsp;&nbsp; <font size=\"3\"> 在 Hadoop 分布式系统中，上层的分布式子系统（MapReduce、YARN、HDFS…）能够共用这个网络通信模块。</font></p>\n<h2 id=\"RPC_工作原理\"><strong>RPC 工作原理</strong></h2>\n<ol>\n<li><h2 id=\"_启动_Hadoop_集群的_DFS、YARN\"><strong> <font color=\"blue\"> <em>启动 Hadoop 集群的 DFS、YARN</em></font></strong></h2>\n<img src=\"/../2014-11-16/hdfs.png\" alt=\"hdfs\"></li>\n<li><h2 id=\"_可以使用_Explorer_的_50070_端口，查看_NameNode\"><strong> <font color=\"blue\"> <em>可以使用 Explorer 的 50070 端口，查看 NameNode</em></font></strong></h2>\n<img src=\"/../2014-11-16/host-yuzhouwan.png\" alt=\"host - yuzhouwan\"></li>\n<li><h2 id=\"_通过_FileSystem_的_get(uri,_conf,_user)_初始化_FS\"><strong> <font color=\"blue\"> <em>通过 FileSystem 的 get(uri, conf, user) 初始化 FS</em></font></strong></h2>\n<img src=\"/../2014-11-16/FileSystem.png\" alt=\"FileSystem\"></li>\n<li><h2 id=\"_抽象类_FileSystem_拥有_13_个子类\"><strong> <font color=\"blue\"> <em>抽象类 FileSystem 拥有 13 个子类</em></font></strong></h2>\n<img src=\"/../2014-11-16/FileSystems.png\" alt=\"FileSystems\"></li>\n<li><h2 id=\"_加载配置文件，并给相应属性赋值\"><strong> <font color=\"blue\"> <em>加载配置文件，并给相应属性赋值</em></font></strong></h2>\n<img src=\"/../2014-11-16/FileSystem.get(uri,conf,user).png\" alt=\"FileSystem.get(uri,conf,user)\"></li>\n<li><h2 id=\"_反射_org-apache-hadoop-hdfs-DistributedFileSystem\"><strong> <font color=\"blue\"> <em>反射 org.apache.hadoop.hdfs.DistributedFileSystem</em></font></strong></h2>\n<img src=\"/../2014-11-16/ReflectionUtils.newInstance--DFS.png\" alt=\"ReflectionUtils.newInstance--DFS\"></li>\n<li><h2 id=\"_调用_initialize(uri,_conf)_初始化_DFS\"><strong> <font color=\"blue\"> <em>调用 initialize(uri, conf) 初始化 DFS</em></font></strong></h2>\n<img src=\"/../2014-11-16/DFS.initialize.png\" alt=\"DFS.initialize\"></li>\n<li><h2 id=\"_获得_DFSClient_代理\"><strong> <font color=\"blue\"> <em>获得 DFSClient 代理</em></font></strong></h2>\n<img src=\"/../2014-11-16/DFSClient(nameNodeUri,rpcNamenode,conf,stats).png\" alt=\"DFSClient(nameNodeUri,rpcNamenode,conf,stats)\"></li>\n<li><h2 id=\"_创建代理\"><strong> <font color=\"blue\"> <em>创建代理</em></font></strong></h2>\n<img src=\"/../2014-11-16/Proxy.png\" alt=\"Proxy\"></li>\n<li><h2 id=\"_让_DFSClient_持有_uri、conf、statistics\"><strong> <font color=\"blue\"> <em>让 DFSClient 持有 uri、conf、statistics</em></font></strong></h2>\n<img src=\"/../2014-11-16/DFSClient.png\" alt=\"DFSClient\"></li>\n<li><h2 id=\"_解析_uri\"><strong> <font color=\"blue\"> <em>解析 uri</em></font></strong></h2>\n<img src=\"/../2014-11-16/URI.create.png\" alt=\"URI.create\"></li>\n<li><h2 id=\"_根据用户组信息中的简单用户名，获取工作路径\"><strong> <font color=\"blue\"> <em>根据用户组信息中的简单用户名，获取工作路径</em></font></strong></h2>\n<img src=\"/../2014-11-16/DFS.getHomeDirectory.png\" alt=\"DFS.getHomeDirectory\"></li>\n<li><h2 id=\"_FileSystem_完成初始化\"><strong> <font color=\"blue\"> <em>FileSystem 完成初始化</em></font></strong></h2>\n<img src=\"/../2014-11-16/DFS-is-ok!!!.png\" alt=\"DFS-is-ok!!!\"></li>\n<li><h2 id=\"_利用_FS-open(path)_打开读取流\"><strong> <font color=\"blue\"> <em>利用 FS.open(path) 打开读取流</em></font></strong></h2>\n<img src=\"/../2014-11-16/DistributedFileSystem.png\" alt=\"DistributedFileSystem\"></li>\n<li><h2 id=\"_解析_path\"><strong> <font color=\"blue\"> <em>解析 path</em></font></strong></h2>\n<img src=\"/../2014-11-16/Path.png\" alt=\"Path\"></li>\n<li><h2 id=\"_装饰_open()_方法\"><strong> <font color=\"blue\"> <em>装饰 open() 方法</em></font></strong></h2>\n<img src=\"/../2014-11-16/FSDataInputStream--open(path).png\" alt=\"FSDataInputStream--open(path)\"></li>\n<li><h2 id=\"_FileSystemLinkResolver_回调函数\"><strong> <font color=\"blue\"> <em>FileSystemLinkResolver 回调函数</em></font></strong></h2>\n<img src=\"/../2014-11-16/DFS.open(f,bufferSize).png\" alt=\"DFS.open(f,bufferSize)\"></li>\n<li><h2 id=\"_HdfsDataInputStream_读取流\"><strong> <font color=\"blue\"> <em>HdfsDataInputStream 读取流</em></font></strong></h2>\n<img src=\"/../2014-11-16/HdfsDataInputStream.png\" alt=\"HdfsDataInputStream\"></li>\n<li><h2 id=\"_FileOutputStream_写入流\"><strong> <font color=\"blue\"> <em>FileOutputStream 写入流</em></font></strong></h2>\n<img src=\"/../2014-11-16/FileOutputStream.png\" alt=\"FileOutputStream\"></li>\n<li><h2 id=\"_缓冲池\"><strong> <font color=\"blue\"> <em>缓冲池</em></font></strong></h2>\n<img src=\"/../2014-11-16/buffSize.png\" alt=\"buffSize\"></li>\n<li><h2 id=\"_IOUtils_封装的拷贝方法\"><strong> <font color=\"blue\"> <em>IOUtils 封装的拷贝方法</em></font></strong></h2>\n<img src=\"/../2014-11-16/IOUtiles.copyBytes(in,out,buffSize).png\" alt=\"IOUtiles.copyBytes(in,out,buffSize)\"></li>\n<li><h2 id=\"_Download_over!\"><strong> <font color=\"blue\"> <em>Download over!</em></font></strong></h2>\n<img src=\"/../2014-11-16/RPC-success.png\" alt=\"RPC-success\"></li>\n</ol>\n","source":"_posts/Hadoop-RPC-源码领略.md","raw":"title: Hadoop RPC 源码领略\ndate: 2014-11-16 18:03:04\ntags:\n- Hadoop\n- RPC\ncategories:\n- Hadoop\n- RPC\n\n---\n\n##__什么是 RPC ?__\n&nbsp;&nbsp; <font size=3> RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。 - - [百度百科][23]\n&nbsp;&nbsp; <font size=3> 远程过程调用（Remote Procedure Call）是一种常用的分布式网络通讯协议，它允许运行于一台计算机的程序调用另一台计算机的子程序，同时将网络的通信细节隐藏起来，使得用户无需额外地外这个交互作用编程。 - - [董的博客][24]\n\n##__为什么要有 RPC ?__\n###**地域性**：\n&nbsp;&nbsp; <font size=3> 当主机不可达时，通过远程调用可以使得终端操作目标机器成为可能。\n###**含糖性**：\n&nbsp;&nbsp; <font size=3> 底层的网络通信细节封装入 API，方便网络分布式系统的开发。\n###**模块化**：\n&nbsp;&nbsp; <font size=3> 在 Hadoop 分布式系统中，上层的分布式子系统（MapReduce、YARN、HDFS...）能够共用这个网络通信模块。\n\n##__RPC 工作原理__\n1. ##__ <font color='blue'> *启动 Hadoop 集群的 DFS、YARN*__\n![hdfs][1]\n2. ##__ <font color='blue'> *可以使用 Explorer 的 50070 端口，查看 NameNode*__\n![host - yuzhouwan][2]\n3. ##__ <font color='blue'> *通过 FileSystem 的 get(uri, conf, user) 初始化 FS*__\n![FileSystem][3]\n4. ##__ <font color='blue'> *抽象类 FileSystem 拥有 13 个子类*__\n![FileSystems][4]\n5. ##__ <font color='blue'> *加载配置文件，并给相应属性赋值*__\n![FileSystem.get(uri,conf,user)][5]\n6. ##__ <font color='blue'> *反射 org.apache.hadoop.hdfs.DistributedFileSystem*__\n![ReflectionUtils.newInstance--DFS][6]\n7. ##__ <font color='blue'> *调用 initialize(uri, conf) 初始化 DFS*__\n![DFS.initialize][7]\n8. ##__ <font color='blue'> *获得 DFSClient 代理*__\n![DFSClient(nameNodeUri,rpcNamenode,conf,stats)][8]\n9. ##__ <font color='blue'> *创建代理*__\n![Proxy][9]\n10. ##__ <font color='blue'> *让 DFSClient 持有 uri、conf、statistics*__\n![DFSClient][10]\n11. ##__ <font color='blue'> *解析 uri*__\n![URI.create][11]\n12. ##__ <font color='blue'> *根据用户组信息中的简单用户名，获取工作路径*__\n![DFS.getHomeDirectory][12]\n13. ##__ <font color='blue'> *FileSystem 完成初始化*__\n![DFS-is-ok!!!][13]\n14. ##__ <font color='blue'> *利用 FS.open(path) 打开读取流*__\n![DistributedFileSystem][14]\n15. ##__ <font color='blue'> *解析 path*__\n![Path][15]\n16. ##__ <font color='blue'> *装饰 open() 方法*__\n![FSDataInputStream--open(path)][16]\n17. ##__ <font color='blue'> *FileSystemLinkResolver 回调函数*__\n![DFS.open(f,bufferSize)][17]\n18. ##__ <font color='blue'> *HdfsDataInputStream 读取流*__\n![HdfsDataInputStream][18]\n19. ##__ <font color='blue'> *FileOutputStream 写入流*__\n![FileOutputStream][19]\n20. ##__ <font color='blue'> *缓冲池*__\n![buffSize][20]\n21. ##__ <font color='blue'> *IOUtils 封装的拷贝方法*__\n![IOUtiles.copyBytes(in,out,buffSize)][21]\n22. ##__ <font color='blue'> *Download over!*__\n![RPC-success][22]\n\n\n[1]:/../2014-11-16/hdfs.png\n[2]:/../2014-11-16/host-yuzhouwan.png\n[3]:/../2014-11-16/FileSystem.png\n[4]:/../2014-11-16/FileSystems.png\n[5]:/../2014-11-16/FileSystem.get(uri,conf,user).png\n[6]:/../2014-11-16/ReflectionUtils.newInstance--DFS.png\n[7]:/../2014-11-16/DFS.initialize.png\n[8]:/../2014-11-16/DFSClient(nameNodeUri,rpcNamenode,conf,stats).png\n[9]:/../2014-11-16/Proxy.png\n[10]:/../2014-11-16/DFSClient.png\n[11]:/../2014-11-16/URI.create.png\n[12]:/../2014-11-16/DFS.getHomeDirectory.png\n[13]:/../2014-11-16/DFS-is-ok!!!.png\n[14]:/../2014-11-16/DistributedFileSystem.png\n[15]:/../2014-11-16/Path.png\n[16]:/../2014-11-16/FSDataInputStream--open(path).png\n[17]:/../2014-11-16/DFS.open(f,bufferSize).png\n[18]:/../2014-11-16/HdfsDataInputStream.png\n[19]:/../2014-11-16/FileOutputStream.png\n[20]:/../2014-11-16/buffSize.png\n[21]:/../2014-11-16/IOUtiles.copyBytes(in,out,buffSize).png\n[22]:/../2014-11-16/RPC-success.png\n\n[23]:http://baike.baidu.com/item/%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8%E5%8D%8F%E8%AE%AE?fromtitle=RPC&fr=aladdin\n[24]:http://dongxicheng.org/\n","slug":"Hadoop-RPC-源码领略","updated":1416129808000,"excerpt":"","_id":"k67davxhfm4cdjf9","comments":true,"layout":"post","photos":[],"link":""},{"title":"Node 模块","date":1415149275000,"tags":["bqus80m5xcxzaorh","j6nschagr2jrxlwa"],"categories":["ifi2x4menzkubm48","42j79qbe5jz59ye4"],"content":"<h2 id=\"为什么要有_Node_模块_?\"><strong>为什么要有 Node 模块 ?</strong></h2>\n<p><font size=\"3\">模块，是 Node 让代码易于重用的一种组织和包装方式</font></p>\n<h2 id=\"创建模块\"><strong>创建模块</strong></h2>\n<figure class=\"highlight node\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">var</span> a = <span class=\"string\">'a'</span>;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">A</span><span class=\"params\">()</span> </span>{</div><div class=\"line\">    <span class=\"built_in\">console</span>.log(a);</div><div class=\"line\">}</div><div class=\"line\">exports.printA = A;</div></pre></td></tr></table></figure>\n\n<h2 id=\"引入模块\"><strong>引入模块</strong></h2>\n<figure class=\"highlight node\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">var</span> a = <span class=\"built_in\">require</span>(<span class=\"string\">'./module_'</span>);</div><div class=\"line\">a.printA();</div></pre></td></tr></table></figure>\n\n<h2 id=\"模块暴露构造函数\"><strong>模块暴露构造函数</strong></h2>\n<figure class=\"highlight node\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//定义</span></div><div class=\"line\"><span class=\"keyword\">var</span> B = <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">(input)</span> </span>{</div><div class=\"line\">    <span class=\"keyword\">this</span>.input = input;</div><div class=\"line\">}</div><div class=\"line\">B.prototype.printB = <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">()</span> </span>{</div><div class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"keyword\">this</span>.input);</div><div class=\"line\">}</div><div class=\"line\"><span class=\"built_in\">module</span>.exports = exports = B;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//调用</span></div><div class=\"line\"><span class=\"keyword\">var</span> B = <span class=\"built_in\">require</span>(<span class=\"string\">'./module_'</span>);</div><div class=\"line\"><span class=\"keyword\">var</span> b = <span class=\"keyword\">new</span> B(<span class=\"string\">'asdf'</span>);</div><div class=\"line\">b.printB();</div></pre></td></tr></table></figure>\n\n<ul>\n<li><font size=\"4\"> <strong><em>exports</em></strong><br><font size=\"3\">&nbsp;&nbsp;只是对 module.exports 的一个全局引用，最初被定义为一个可以添加属性的空对象</font></font></li>\n<li><font size=\"4\"> <strong><em>exports.printA</em></strong><br><font size=\"3\">&nbsp;&nbsp;是 module.exports.printA 的简写</font></font></li>\n<li><font size=\"4\"> <strong><em>exports = B</em></strong><br><font size=\"3\">&nbsp;&nbsp;将会打破 module.exports 和 exports 之间的引用关系</font></font></li>\n<li><font size=\"4\"> <strong><em>module.exports = exports</em></strong><br><font size=\"3\">&nbsp;&nbsp;可以修复链接</font></font></li>\n</ul>\n<h2 id=\"Module_加载流程\"><strong>Module 加载流程</strong></h2>\n<p><img src=\"/../2014-11-5/steps-to-finding-a-module.png\" alt=\"module\"></p>\n<h2 id=\"目录模块\"><strong>目录模块</strong></h2>\n<p><img src=\"/../2014-11-5/steps-to-finding-a-main-file.png\" alt=\"package.json\"></p>\n<h2 id=\"Monkey_Patching\"><strong>Monkey Patching</strong></h2>\n<p><font size=\"3\">&nbsp;&nbsp;Node 将模块作为对象缓存起来</font></p>\n<p><font size=\"3\">&nbsp;&nbsp;第一个文件会将模块返回的数据存到程序的内存中，第二个文件就不用再去访问和计算模块的源文件了</font></p>\n<p><font size=\"3\">&nbsp;&nbsp;并且第二次引入有机会修改缓存的数据</font></p>\n","source":"_posts/Node-模块.md","raw":"title: Node 模块\ndate: 2014-11-05 09:01:15\ntags:\n- Node.js\n- Module\ncategories:\n- Node.js\n- Module\n---\n##__为什么要有 Node 模块 ?__\n<font size=3>模块，是 Node 让代码易于重用的一种组织和包装方式\n\n##__创建模块__\n```node\nvar a = 'a';\nfunction A() {\n    console.log(a);\n}\nexports.printA = A;\n```\n\n##__引入模块__\n```node\nvar a = require('./module_');\na.printA();\n```\n\n##__模块暴露构造函数__\n```node\n//定义\nvar B = function (input) {\n    this.input = input;\n}\nB.prototype.printB = function () {\n    console.log(this.input);\n}\nmodule.exports = exports = B;\n\n//调用\nvar B = require('./module_');\nvar b = new B('asdf');\nb.printB();\n```\n+ <font size=4> __*exports*__\n<font size=3>&nbsp;&nbsp;只是对 module.exports 的一个全局引用，最初被定义为一个可以添加属性的空对象\n+ <font size=4> __*exports.printA*__\n<font size=3>&nbsp;&nbsp;是 module.exports.printA 的简写\n+ <font size=4> __*exports = B*__\n<font size=3>&nbsp;&nbsp;将会打破 module.exports 和 exports 之间的引用关系\n+ <font size=4> __*module.exports = exports*__\n<font size=3>&nbsp;&nbsp;可以修复链接\n\n##__Module 加载流程__\n![module][1]\n\n##__目录模块__\n![package.json][2]\n\n##__Monkey Patching__\n<font size=3>&nbsp;&nbsp;Node 将模块作为对象缓存起来\n<font size=3>&nbsp;&nbsp;第一个文件会将模块返回的数据存到程序的内存中，第二个文件就不用再去访问和计算模块的源文件了\n<font size=3>&nbsp;&nbsp;并且第二次引入有机会修改缓存的数据\n\n[1]:/../2014-11-5/steps-to-finding-a-module.png\n[2]:/../2014-11-5/steps-to-finding-a-main-file.png\n\n\n\n\n","slug":"Node-模块","updated":1416131502000,"excerpt":"","_id":"v5tsu8wyv17axfu8","comments":true,"layout":"post","photos":[],"link":""},{"title":"Python Libraries","date":1423152520000,"tags":["fi8l4hi69ijj68zv"],"categories":["80hi5d71gh1mfgtr"],"content":"<h2 id=\"什么是_Python?\"><strong><font color=\"blue\"><em>什么是 Python?</em></font></strong></h2>\n<p>&nbsp; <font size=\"3\"><em>Python is a programming language that lets you work quickly and integrate systems more effectively.</em><font size=\"2\"><a href=\"https://www.python.org/\" target=\"_blank\" rel=\"external\"> - - Python Official Site</a></font></font></p>\n<h2 id=\"为什么要有_Python?\"><strong><font color=\"blue\"><em>为什么要有 Python?</em></font></strong></h2>\n<h3 id=\"胶水语言\"><strong>胶水语言</strong></h3>\n<pre><code>胶水语言，能够把用其他语言制作的各种模块 ( 尤其是 <span class=\"keyword\">C</span>/<span class=\"keyword\">C</span>++ ) 很轻松地联结在一起\n</code></pre><h3 id=\"脚本语言\"><strong>脚本语言</strong></h3>\n<pre><code>ABC 语言的一种继承\n缩短传统的 编写 - 编译 - 链接 - 运行 ( <span class=\"keyword\">edit</span>-compile-link-run ) 过程\n</code></pre><h2 id=\"Python_标准库\"><strong><font color=\"blue\"><em>Python 标准库</em></font></strong></h2>\n<p><a href=\"https://github.com/python/cpython/blob/master/Lib/argparse.py\" target=\"_blank\" rel=\"external\">argparse</a><br><a href=\"https://github.com/python/cpython/blob/master/Lib/ftplib.py\" target=\"_blank\" rel=\"external\">ftplib</a><br><a href=\"https://github.com/python/cpython/tree/master/Lib/json\" target=\"_blank\" rel=\"external\">json</a><br><a href=\"https://github.com/python/cpython/tree/master/Lib/urllib\" target=\"_blank\" rel=\"external\">urllib</a></p>\n<h2 id=\"Python_第三方库\"><strong><font color=\"blue\"><em>Python 第三方库</em></font></strong></h2>\n<p><a href=\"https://github.com/pika/pika\" target=\"_blank\" rel=\"external\">Pika</a></p>\n<h2 id=\"Python_工程工具\"><strong><font color=\"blue\"><em>Python 工程工具</em></font></strong></h2>\n<p><a href=\"https://testrun.org/tox\" target=\"_blank\" rel=\"external\">Tox</a><br><a href=\"https://github.com/pypa/virtualenv\" target=\"_blank\" rel=\"external\">virtualenv</a></p>\n","source":"_posts/Python-Libraries.md","raw":"title: Python Libraries\ndate: 2015-02-06 00:08:40\ntags:\n- Python\ncategories:\n- Python\n---\n\n## __<font color='blue'>*什么是 Python?*__\n\n&nbsp; <font size=3>_Python is a programming language that lets you work quickly and integrate systems more effectively._<font size=2>[ - - Python Official Site][1]\n\n## __<font color='blue'>*为什么要有 Python?*__\n\n###__胶水语言__\n\t胶水语言，能够把用其他语言制作的各种模块 ( 尤其是 C/C++ ) 很轻松地联结在一起\n\n###__脚本语言__\n\tABC 语言的一种继承\n\t缩短传统的 编写 - 编译 - 链接 - 运行 ( edit-compile-link-run ) 过程\n\n## __<font color='blue'>*Python 标准库*__\n\n[argparse][21]\n[ftplib][22]\n[json][23]\n[urllib][24]\n\n## __<font color='blue'>*Python 第三方库*__\n\n[Pika][31]\n\n## __<font color='blue'>*Python 工程工具*__\n\n[Tox][41]\n[virtualenv][42]\n\n\n\n\n\n\n\n[1]:https://www.python.org/\n[21]:https://github.com/python/cpython/blob/master/Lib/argparse.py\n[22]:https://github.com/python/cpython/blob/master/Lib/ftplib.py\n[23]:https://github.com/python/cpython/tree/master/Lib/json\n[24]:https://github.com/python/cpython/tree/master/Lib/urllib\n[31]:https://github.com/pika/pika\n[41]:https://testrun.org/tox\n[42]:https://github.com/pypa/virtualenv\n","slug":"Python-Libraries","updated":1423233648000,"excerpt":"","_id":"8asqaq0ueugeyyol","comments":true,"layout":"post","photos":[],"link":""},{"title":"Qcon 2015 见闻之一：猿题库","date":1429973835000,"tags":["50ciaur9vavdib6s","e1tjoskwhawonzzl"],"categories":["j75ue2n8rvuhvu7u"],"content":"<h2 id=\"什么是_‘猿题库’_?\"><strong><font color=\"blue\"><em>什么是 ‘猿题库’ ?</em></font></strong></h2>\n<p>&nbsp;&nbsp; <font size=\"3\"> 初高中刷题利器 - - <a href=\"http://yuantiku.com/\" target=\"_blank\" rel=\"external\">猿题库 官网</a></font></p>\n<p>&nbsp;&nbsp; <font size=\"3\"> 猿：猿到人的进化 - - <a href=\"http://qconbeijing.com/\" target=\"_blank\" rel=\"external\">QCon</a></font></p>\n<p>&nbsp;&nbsp; <font size=\"3\"> 猿题库是一款手机智能做题软件，目前已经完成对初中和高中6个年级的全面覆盖。 - - <a href=\"http://baike.baidu.com/view/10119401.htm\" target=\"_blank\" rel=\"external\">百度百科</a></font></p>\n<p>&nbsp;&nbsp; <font size=\"3\"> 2014年7月，猿题库宣布完成1500万美元的C轮融资。融资完成后，猿题库的估值达到1.25亿美元。至此，公司刚刚成立两年。 - - <a href=\"http://tech.163.com/14/0727/09/A25C1HDC000915BF.html\" target=\"_blank\" rel=\"external\">网易科技</a></font></p>\n<h2 id=\"猿题库_如何在_在线教育领域_应用_ML?\"><strong><font color=\"blue\"><em>猿题库 如何在 在线教育领域 应用 ML?</em></font></strong></h2>\n<h3 id=\"小猿搜题\"><strong>小猿搜题</strong></h3>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"input\"><span class=\"prompt\">Photo(手机横屏采集题目) -&gt;</span> <span class=\"constant\">Prepare</span> -&gt; <span class=\"constant\">Split</span> -&gt; <span class=\"constant\">CNN</span>识别 -&gt; <span class=\"constant\">NLP</span>纠错 -&gt; 搜索 -&gt; 返回题目</span></div><div class=\"line\">                       -&gt; 插图匹配 ---------------------------- -&gt;</div></pre></td></tr></table></figure>\n\n<h4 id=\"①_Photo\">① Photo</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">内容多样，模糊图(<span class=\"number\">30</span>%)，公式(<span class=\"number\">50</span>%)</div></pre></td></tr></table></figure>\n\n<h4 id=\"②_Prepare\">② Prepare</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">横屏(转向)，黑底白字</div></pre></td></tr></table></figure>\n\n<h4 id=\"③_Split\">③ Split</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">公式分词(根号)</div></pre></td></tr></table></figure>\n\n<h4 id=\"④_CNN识别\">④ CNN识别</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"input\"><span class=\"prompt\">卷积神经网络(Model)、标记数据、自动生成、DL(SGD -&gt;</span> 高斯牛顿)</span></div></pre></td></tr></table></figure>\n\n<h4 id=\"⑤_NLP纠错\">⑤ NLP纠错</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"input\"><span class=\"prompt\">语言模型(example: '回边形' -&gt;</span> <span class=\"string\">'四边形'</span>)</span></div></pre></td></tr></table></figure>\n\n<h4 id=\"⑥_搜索\">⑥ 搜索</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">分词、inverted-index、排序、<span class=\"constant\">Learning</span> to <span class=\"constant\">Rank</span>、<span class=\"constant\">GBRT</span></div></pre></td></tr></table></figure>\n\n<h4 id=\"⑦_插图匹配\">⑦ 插图匹配</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"constant\">SIFT</span>、高命中(直接进行 ⑥)</div></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"学生能力预测\"><strong>学生能力预测</strong></h3>\n<h4 id=\"&nbsp;&nbsp;项目反应理论\">&nbsp;&nbsp;项目反应理论</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"input\"><span class=\"prompt\">IRT -&gt;</span> <span class=\"constant\">FTRL</span></span></div></pre></td></tr></table></figure>\n\n<h4 id=\"&nbsp;&nbsp;特征\">&nbsp;&nbsp;特征</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">用户(学校 + 地区 + 目标考试)、题目(知识点 + 关键字)、时序(距离目标考试时间)</div></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"猿辅导老师推荐\"><strong>猿辅导老师推荐</strong></h3>\n<h4 id=\"&nbsp;&nbsp;推荐系统\">&nbsp;&nbsp;推荐系统</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">冷启动、<span class=\"constant\">Item</span>-base</div></pre></td></tr></table></figure>\n\n<h4 id=\"&nbsp;&nbsp;ML\">&nbsp;&nbsp;ML</h4>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">logistic factorization machine、<span class=\"constant\">E</span>&<span class=\"constant\">E</span>(挖掘潜力)</div></pre></td></tr></table></figure>\n\n<h2 id=\"猿题库_的未来走向\"><strong><font color=\"blue\"><em>猿题库 的未来走向</em></font></strong></h2>\n<h3 id=\"知识图谱\"><strong>知识图谱</strong></h3>\n<p> &nbsp;&nbsp; 学生成长之路</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">题目 + 学生 = 提升后的学生 (可量化)</div></pre></td></tr></table></figure>\n\n<h3 id=\"手写识别\"><strong>手写识别</strong></h3>\n<ul>\n<li>手写搜题</li>\n<li>解答题</li>\n<li>自动判卷</li>\n</ul>\n<h3 id=\"高考机器\"><strong>高考机器</strong></h3>\n<pre><code>机器自动出题、做题\n</code></pre><h3 id=\"智能芯片\"><strong>智能芯片</strong></h3>\n<pre><code>极短的时间内，将十几年需要学习的知识学习完\n</code></pre><p><font color=\"red\"><strong> 最后感谢：猿题库 研究部总监 — <a href=\"http://2015.qconbeijing.com/speakers/201685\" target=\"_blank\" rel=\"external\">邓澍军</a> 的精彩演讲！</strong></font></p>\n","source":"_posts/Qcon-2015-见闻之一：猿题库.md","raw":"title: Qcon 2015 见闻之一：猿题库\ndate: 2015-04-25 22:57:15\ntags:\n - Qcon\n - 猿题库\ncategories:\n - Qcon\n---\n\n## __<font color='blue'>*什么是 '猿题库' ?*__\n\n&nbsp;&nbsp; <font size=3> 初高中刷题利器 - - [猿题库 官网][1]\n\n&nbsp;&nbsp; <font size=3> 猿：猿到人的进化 - - [QCon][2]\n\n&nbsp;&nbsp; <font size=3> 猿题库是一款手机智能做题软件，目前已经完成对初中和高中6个年级的全面覆盖。 - - [百度百科][3]\n\n&nbsp;&nbsp; <font size=3> 2014年7月，猿题库宣布完成1500万美元的C轮融资。融资完成后，猿题库的估值达到1.25亿美元。至此，公司刚刚成立两年。 - - [网易科技][4]\n\n\n## __<font color='blue'>*猿题库 如何在 在线教育领域 应用 ML?*__\n\n### __小猿搜题__\n```ruby\nPhoto(手机横屏采集题目) -> Prepare -> Split -> CNN识别 -> NLP纠错 -> 搜索 -> 返回题目\n                       -> 插图匹配 ---------------------------- -> \n```\n\n#### ① Photo\n```ruby\n内容多样，模糊图(30%)，公式(50%)\n```\n\n#### ② Prepare\n```ruby\n横屏(转向)，黑底白字\n```\n\n#### ③ Split\n```ruby\n公式分词(根号)\n```\n\n#### ④ CNN识别\n```ruby\n卷积神经网络(Model)、标记数据、自动生成、DL(SGD -> 高斯牛顿)\n```\n\n#### ⑤ NLP纠错\n```ruby\n语言模型(example: '回边形' -> '四边形')\n```\n\n#### ⑥ 搜索\n```ruby\n分词、inverted-index、排序、Learning to Rank、GBRT\n```\n\n#### ⑦ 插图匹配\n```ruby\nSIFT、高命中(直接进行 ⑥)\n```\n\n------------\n\n\n### __学生能力预测__\n\n#### &nbsp;&nbsp;项目反应理论\n```ruby\nIRT -> FTRL\n```\n\n#### &nbsp;&nbsp;特征\n```ruby\n用户(学校 + 地区 + 目标考试)、题目(知识点 + 关键字)、时序(距离目标考试时间)\n```\n\n------------\n\n### __猿辅导老师推荐__\n\n#### &nbsp;&nbsp;推荐系统\n```ruby\n冷启动、Item-base\n```\n\n#### &nbsp;&nbsp;ML\n```ruby\nlogistic factorization machine、E&E(挖掘潜力)\n```\n\n\n\n## __<font color='blue'>*猿题库 的未来走向*__\n\n### __知识图谱__\n &nbsp;&nbsp; 学生成长之路\n```ruby\n题目 + 学生 = 提升后的学生 (可量化)\n```\n\n### __手写识别__\n - 手写搜题\n - 解答题\n - 自动判卷\n\n### __高考机器__\n\t机器自动出题、做题\n\n### __智能芯片__\n\t极短的时间内，将十几年需要学习的知识学习完\n\n\n\n<font color='red'>__ 最后感谢：猿题库 研究部总监 -- [邓澍军][5] 的精彩演讲！__\n\n\n[1]:http://yuantiku.com/\n[2]:http://qconbeijing.com/\n[3]:http://baike.baidu.com/view/10119401.htm\n[4]:http://tech.163.com/14/0727/09/A25C1HDC000915BF.html\n[5]:http://2015.qconbeijing.com/speakers/201685\n","slug":"Qcon-2015-见闻之一：猿题库","updated":1429978624000,"excerpt":"","_id":"iddp8bje6jh1iem0","comments":true,"layout":"post","photos":[],"link":""},{"title":"SSO","date":1416130099000,"tags":["8vx42s7rnc3dvd7k","3i102onxaw6lk3mf","xcnxrp14cozuu482"],"categories":["62jx5vbvtw96qrcg"],"content":"<h2 id=\"SSO_是什么_?\"><strong>SSO 是什么 ?</strong></h2>\n<p><font size=\"3\"> &nbsp;&nbsp; <em>SSO <font size=\"2\"> (Single Sign-on)</font></em> , 单点登录</font></p>\n<p><font size=\"3\"> &nbsp; 一个多系统共存的环境下，用户在一处登录后，就不用在其他系统中登录，也就是用户的一次登录能得到其他所有系统的信任 - - <a href=\"http://blog.csdn.net/cutesource/article/details/5838693\" target=\"_blank\" rel=\"external\">cutesource</a></font></p>\n<p><font size=\"3\"> &nbsp; 在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制 - - <a href=\"http://baike.baidu.com/subview/190743/15011802.htm?fr=aladdin\" target=\"_blank\" rel=\"external\">百度百科</a></font></p>\n<h2 id=\"为什么要有_SSO_?\"><strong>为什么要有 SSO ?</strong></h2>\n<p><font size=\"3\"> &nbsp; 尤其，大型网站背后是成百上千的子系统，用户一次操作或交易可能涉及到几十个子系统的协作。</font></p>\n<p><font size=\"3\"> &nbsp; 如果每次子系统都需要用户认证，不仅用户会疯掉，各子系统也会为这种重复认证的逻辑搞疯掉。</font></p>\n<h2 id=\"SSO_框架\"><strong>SSO 框架</strong></h2>\n<h3 id=\"&nbsp;_CAS_(Central_Authentication_Server)\">&nbsp; <em><strong>CAS</strong> <font size=\"2\"> (Central Authentication Server)</font></em></h3>\n<p><font size=\"3\"> &nbsp;&nbsp;&nbsp;&nbsp; 是 Yale 大学发起的一个开源项目，据统计，大概每 10 个采用开源构建 Web SSO 的 Java 项目，就有 8 个使用 CAS</font></p>\n<h3 id=\"&nbsp;_Passport_认证服务\">&nbsp; <strong><em>Passport 认证服务</em></strong></h3>\n<p><font size=\"3\"> &nbsp;&nbsp;&nbsp;&nbsp; ASP.NET 基于 Form 的认证方法</font></p>\n","source":"_posts/SSO.md","raw":"title: SSO\ndate: 2014-11-16 17:28:19\ntags:\n- SSO\n- Session\n- Cookie\n\ncategories:\n- SSO\n\n---\n\n##__SSO 是什么 ?__\n<font size=3> &nbsp;&nbsp; *SSO <font size=2> (Single Sign-on)* , 单点登录\n<font size=3> &nbsp; 一个多系统共存的环境下，用户在一处登录后，就不用在其他系统中登录，也就是用户的一次登录能得到其他所有系统的信任 - - [cutesource][1]\n<font size=3> &nbsp; 在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制 - - [百度百科][2]\n\n##__为什么要有 SSO ?__\n<font size=3> &nbsp; 尤其，大型网站背后是成百上千的子系统，用户一次操作或交易可能涉及到几十个子系统的协作。\n<font size=3> &nbsp; 如果每次子系统都需要用户认证，不仅用户会疯掉，各子系统也会为这种重复认证的逻辑搞疯掉。\n\n\n##__SSO 框架__\n\n### &nbsp; *__CAS__ <font size=2> (Central Authentication Server)*\n<font size=3> &nbsp;&nbsp;&nbsp;&nbsp; 是 Yale 大学发起的一个开源项目，据统计，大概每 10 个采用开源构建 Web SSO 的 Java 项目，就有 8 个使用 CAS\n\n\n### &nbsp; __*Passport 认证服务*__\n<font size=3> &nbsp;&nbsp;&nbsp;&nbsp; ASP.NET 基于 Form 的认证方法\n\n\n[1]:http://blog.csdn.net/cutesource/article/details/5838693\n[2]:http://baike.baidu.com/subview/190743/15011802.htm?fr=aladdin\n","slug":"SSO","updated":1416131117000,"excerpt":"","_id":"olrtd7b14rhsopss","comments":true,"layout":"post","photos":[],"link":""},{"title":"Session","date":1416038136000,"tags":["3i102onxaw6lk3mf","lg5ujhq2pmtkmi0y","438n5ijdoh4276rx","2mrmj7hdj23lrf8v","5nl39kev5x2rq69n","fnxfe9uy8e6qhde0","8vx42s7rnc3dvd7k","o22325zmryeb14yf"],"categories":["x8unynvslphmme81"],"content":"<h2 id=\"Session_是什么_?\"><strong>Session 是什么 ?</strong></h2>\n<p><font size=\"3\">&nbsp;&nbsp;指一个终端用户与交互系统进行通信的时间间隔，通常指从注册进入系统到注销退出系统之间所经历的时间 - - <a href=\"http://baike.baidu.com/view/25258.htm?fr=aladdin\" target=\"_blank\" rel=\"external\">百度百科</a><br></font></p>\n<p><font size=\"3\">&nbsp;&nbsp;代表服务器与浏览器之间的一次会话过程，这个过程是连续的，也可以是时断时续的 - - <a href=\"http://lavasoft.blog.51cto.com/62575/275589\" target=\"_blank\" rel=\"external\">熔岩的博客</a><br></font></p>\n<p><font size=\"3\">&nbsp;&nbsp;在 web 开发语境下，含义是指一类用来在客户端与服务器之间保持状态的解决方案 - - <a href=\"http://www.2cto.com/kf/201206/135471.html\" target=\"_blank\" rel=\"external\">我来说两句</a><br></font></p>\n<ul>\n<li><em>Java</em></li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">- javax.servlet.http.HttpSession</div></pre></td></tr></table></figure>\n\n<ul>\n<li><em>PHP</em></li>\n</ul>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">- <span class=\"variable\">$_session</span></div></pre></td></tr></table></figure>\n\n<ul>\n<li><em>JSP</em></li>\n</ul>\n<figure class=\"highlight jsp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">- HttpSession</div></pre></td></tr></table></figure>\n\n<ul>\n<li><em>Hibernate</em></li>\n</ul>\n<figure class=\"highlight hibernate\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">- org.hibernate <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Session</span></span></div></pre></td></tr></table></figure>\n\n<ul>\n<li><em>WebLogic</em></li>\n</ul>\n<figure class=\"highlight weblogic\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"deletion\">- Weblogic Server session</span></div></pre></td></tr></table></figure>\n\n<h2 id=\"为什么要有_Session_?\"><strong>为什么要有 Session ?</strong></h2>\n<p><font size=\"3\">&nbsp;&nbsp;HTTP 本身是无状态的，这与 HTTP 协议本身的目的是相符的。<br></font></p>\n<p><font size=\"3\">&nbsp;&nbsp;当客户每次访问 web 页面，服务器重新打开新的会话时，为了维护其上下文信息（记住同一个用户）。<br></font></p>\n<p><font size=\"3\">&nbsp;&nbsp;由于此类种种场景，需要让 HTTP 协议成为有状态的。<br></font></p>\n<h2 id=\"Session_工作原理_-\"><strong>Session 工作原理 .</strong></h2>\n<p><font size=\"3\">&nbsp;&nbsp;session 机制是一种服务器端的机制，服务器使用一种类似于散列表的结构来保存信息。</font></p>\n<p><img src=\"/../2014-11-15/session.png\" alt=\"session\"></p>\n<h2 id=\"那些年一起踩过的坑_!\"><strong>那些年一起踩过的坑 !</strong></h2>\n<h3 id=\"session_的创建\"><em>session 的创建</em></h3>\n<p><font size=\"3\">&nbsp;&nbsp;&nbsp;&nbsp;session 不是在客户端访问 server 的时候就创建，而是在服务器的某个构建 session 的语句被调用时</font></p>\n<ul>\n<li><em>PHP</em></li>\n</ul>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">- session_start()</div></pre></td></tr></table></figure>\n\n<ul>\n<li><em>JSP</em></li>\n</ul>\n<figure class=\"highlight jsp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">- 内置对象 session</div></pre></td></tr></table></figure>\n\n<ul>\n<li><em>Java</em></li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">-  HttpServletRequest.getSession(<span class=\"keyword\">true</span>)</div></pre></td></tr></table></figure>\n\n<ul>\n<li><em>Hibernate</em></li>\n</ul>\n<figure class=\"highlight hibernate\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">- <span class=\"keyword\">new</span> <span class=\"keyword\">Configuration</span>.configure(<span class=\"string\">\"hibernate.cfg.xml\"</span>).buildSessionFactory().openSesssion()</div></pre></td></tr></table></figure>\n\n<h3 id=\"SSO_(Single_sign_on)\"><em><a href=\"http://www.yuzhouwan.com/2014/11/16/SSO/\" target=\"_blank\" rel=\"external\">SSO</a> (Single sign on)</em></h3>\n<p><font size=\"3\">  按照 Servlet 规范，session 的作用域应该仅仅限于当前应用程序下，不同的应用程序之间是不能够相互访问对方的 session 的。</font></p>\n<p><font size=\"3\">  各个应用服务器从实际效果上都遵守了这一规范，但是实现的细节却可能各有不同，因此解决跨应用程序 session 共享的方法也不尽相同。</font></p>\n<p><font size=\"3\">  可以借助于第三方的力量，比如使用文件、数据库、JMS 或者客户端 cookie，URL 参数或者隐藏字段等手段。</font></p>\n<p><font size=\"3\">  还有一种较为方便的做法，就是把一个应用程序的 session 放到 ServletContext 中取得前一个应用程序的引用。</font></p>\n","source":"_posts/Session.md","raw":"title: Session\ndate: 2014-11-15 15:55:36\ntags:\n- Session\n- Java\n- PHP\n- JSP\n- Hibernate\n- WebLogic\n- SSO\n- HTTP\ncategories:\n- Session\n\n---\n\n\n##__Session 是什么 ?__\n<font size=3>&nbsp;&nbsp;指一个终端用户与交互系统进行通信的时间间隔，通常指从注册进入系统到注销退出系统之间所经历的时间 - - [百度百科][1]<br/>\n<font size=3>&nbsp;&nbsp;代表服务器与浏览器之间的一次会话过程，这个过程是连续的，也可以是时断时续的 - - [熔岩的博客][2]<br/>\n<font size=3>&nbsp;&nbsp;在 web 开发语境下，含义是指一类用来在客户端与服务器之间保持状态的解决方案 - - [我来说两句][3]<br/>\n\n+ *Java*\n```java\n\t- javax.servlet.http.HttpSession\n```\n+ *PHP*\n```php\n\t- $_session\n```\n+ *JSP*\n```jsp\n\t- HttpSession\n```\n+ *Hibernate*\n```hibernate\n\t- org.hibernate interface Session\n```\n+ *WebLogic*\n```weblogic\n\t- Weblogic Server session\n```\n\n\n##__为什么要有 Session ?__\n<font size=3>&nbsp;&nbsp;HTTP 本身是无状态的，这与 HTTP 协议本身的目的是相符的。<br/>\n<font size=3>&nbsp;&nbsp;当客户每次访问 web 页面，服务器重新打开新的会话时，为了维护其上下文信息（记住同一个用户）。<br/>\n<font size=3>&nbsp;&nbsp;由于此类种种场景，需要让 HTTP 协议成为有状态的。<br/>\n\n\n##__Session 工作原理 .__\n<font size=3>&nbsp;&nbsp;session 机制是一种服务器端的机制，服务器使用一种类似于散列表的结构来保存信息。\n\n![session][4]\n\n\n##__那些年一起踩过的坑 !__\n\n###  *session 的创建*\n\n<font size=3>&nbsp;&nbsp;&nbsp;&nbsp;session 不是在客户端访问 server 的时候就创建，而是在服务器的某个构建 session 的语句被调用时\n+ *PHP*\n```php\n\t- session_start()\n```\n+ *JSP*\n```jsp\n\t- 内置对象 session\n```\n+ *Java*\n```java\n\t-  HttpServletRequest.getSession(true)\n```\n+ *Hibernate*\n```hibernate\n\t- new Configuration.configure(\"hibernate.cfg.xml\").buildSessionFactory().openSesssion()\n```\n\n### *[SSO][5] (Single sign on)*\n\n<font size=3>  按照 Servlet 规范，session 的作用域应该仅仅限于当前应用程序下，不同的应用程序之间是不能够相互访问对方的 session 的。\n\n<font size=3>  各个应用服务器从实际效果上都遵守了这一规范，但是实现的细节却可能各有不同，因此解决跨应用程序 session 共享的方法也不尽相同。\n\n<font size=3>  可以借助于第三方的力量，比如使用文件、数据库、JMS 或者客户端 cookie，URL 参数或者隐藏字段等手段。\n\n<font size=3>  还有一种较为方便的做法，就是把一个应用程序的 session 放到 ServletContext 中取得前一个应用程序的引用。\n\n\n\n[1]:http://baike.baidu.com/view/25258.htm?fr=aladdin\n[2]:http://lavasoft.blog.51cto.com/62575/275589\n[3]:http://www.2cto.com/kf/201206/135471.html\n[4]:/../2014-11-15/session.png\n[5]:http://www.yuzhouwan.com/2014/11/16/SSO/\n","slug":"Session","updated":1416131455000,"excerpt":"","_id":"e62ebblg305ndghv","comments":true,"layout":"post","photos":[],"link":""},{"title":"Storm 与 Kafka 的整合之三：Combination","date":1431239288000,"tags":["jhce84bmw2q9nu7n","11cpxxkwjnfgt7bl"],"categories":["k8prskk4oioqqy4b","68a0veepaufante1"],"content":"<h2 id=\"搭建_Storm_和_Kafka_的基础环境\"><strong><font color=\"blue\"><em>搭建 Storm 和 Kafka 的基础环境</em></font></strong></h2>\n<h3 id=\"搭建_Storm_集群_(本地模式)\"><strong>搭建 <a href=\"http://storm.apache.org/documentation/Home.html\" target=\"_blank\" rel=\"external\">Storm</a> 集群 (本地模式)</strong></h3>\n<h3 id=\"搭建_Kafka_环境\"><strong>搭建 <a href=\"http://kafka.apache.org/documentation.html\" target=\"_blank\" rel=\"external\">Kafka</a> 环境</strong></h3>\n<h3 id=\"启动_Kafka\"><strong>启动 Kafka</strong></h3>\n<h4 id=\"-_start_the_zookeeper_and_kafka_server\">- start the zookeeper and kafka server</h4>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">bin/zookeeper-server-start.<span class=\"keyword\">sh</span> config/zookeeper.properties</div></pre></td></tr></table></figure>\n\n\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">bin/kafka-server-<span class=\"operator\"><span class=\"keyword\">start</span>.sh config/<span class=\"keyword\">server</span>.properties</span></div></pre></td></tr></table></figure>\n\n<h4 id=\"-_create_a_topic\">- create a topic</h4>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">bin/kafka</span><span class=\"literal\">-</span><span class=\"comment\">topics</span><span class=\"string\">.</span><span class=\"comment\">sh</span> <span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"comment\">create</span> <span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"comment\">zookeeper</span> <span class=\"comment\">localhost:2181</span> <span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"comment\">replication</span><span class=\"literal\">-</span><span class=\"comment\">factor</span> <span class=\"comment\">1</span> <span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"comment\">partitions</span> <span class=\"comment\">1</span> <span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"comment\">topic</span> <span class=\"comment\">my</span><span class=\"literal\">-</span><span class=\"comment\">replicated</span><span class=\"literal\">-</span><span class=\"comment\">topic</span></div></pre></td></tr></table></figure>\n\n<p><font size=\"2\">&nbsp;&nbsp;&nbsp;&nbsp;We can now see that topic if we run the list topic command:</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">bin/kafka-topics.<span class=\"keyword\">sh</span> --<span class=\"keyword\">list</span> --zookeeper localhos<span class=\"variable\">t:2181</span></div></pre></td></tr></table></figure>\n\n<h2 id=\"发送_Message_往_Kafka\"><strong><font color=\"blue\"><em>发送 Message 往 Kafka</em></font></strong></h2>\n<h3 id=\"编写_SendMessageToKafka\"><strong>编写 SendMessageToKafka</strong></h3>\n<ol>\n<li><font size=\"2\"> 根据 kafka 中 cluster 的属性，定义好 Producer</font></li>\n<li><font size=\"2\"> 利用 Producer.send(KeyedMessage) 方法，将 “topic - message” 发送给 Kafka</font></li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SendMessageToKafka</span> </span>{</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Producer&lt;String, String&gt; producer;</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">init</span>() {</div><div class=\"line\">\t\tProperties props = <span class=\"keyword\">new</span> Properties();</div><div class=\"line\">\t\tprops.put(<span class=\"string\">\"zk.connect\"</span>, <span class=\"string\">\"192.168.1.201:2181\"</span>);</div><div class=\"line\">\t\tprops.put(<span class=\"string\">\"serializer.class\"</span>, <span class=\"string\">\"kafka.serializer.StringEncoder\"</span>);</div><div class=\"line\">\t\tprops.put(<span class=\"string\">\"metadata.broker.list\"</span>, <span class=\"string\">\"192.168.1.201:9092\"</span>);</div><div class=\"line\">\t\tProducerConfig config = <span class=\"keyword\">new</span> ProducerConfig(props);</div><div class=\"line\">\t\tproducer = <span class=\"keyword\">new</span> Producer&lt;String, String&gt;(config);</div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span>(String... arg) {</div><div class=\"line\"></div><div class=\"line\">\t\tinit();</div><div class=\"line\"></div><div class=\"line\">\t\tKeyedMessage&lt;String, String&gt; data = <span class=\"keyword\">new</span> KeyedMessage&lt;String, String&gt;(</div><div class=\"line\">\t\t\t\t<span class=\"string\">\"my-replicated-topic\"</span>, <span class=\"string\">\"asdf2015\"</span>);</div><div class=\"line\">\t\tproducer.send(data);</div><div class=\"line\">\t\tproducer.close();</div><div class=\"line\"></div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<h3 id=\"run_the_main_method\"><strong>run the main method</strong></h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">com.yuzhouwan.hadoop.customer_behaviour_analyse.kafka.SendMessageToKafka</div></pre></td></tr></table></figure>\n\n<h3 id=\"check_out_the_message_that_tht_broker_catched\"><strong>check out the message that tht broker catched</strong></h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">bin/kafka</span><span class=\"literal\">-</span><span class=\"comment\">console</span><span class=\"literal\">-</span><span class=\"comment\">consumer</span><span class=\"string\">.</span><span class=\"comment\">sh</span> <span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"comment\">zookeeper</span> <span class=\"comment\">localhost:2181</span> <span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"comment\">from</span><span class=\"literal\">-</span><span class=\"comment\">beginning</span> <span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"comment\">topic</span> <span class=\"comment\">my</span><span class=\"literal\">-</span><span class=\"comment\">replicated</span><span class=\"literal\">-</span><span class=\"comment\">topic</span></div></pre></td></tr></table></figure>\n\n<p>Then, u will see that the ‘asdf2015’ message was sent sucessfully.</p>\n<h2 id=\"从_Kafka_中获得_Message\"><strong><font color=\"blue\"><em>从 Kafka 中获得 Message</em></font></strong></h2>\n<h3 id=\"编写_TestMessageScheme\"><strong>编写 TestMessageScheme</strong></h3>\n<p><font size=\"2\"> 在 deserialize(byte[]) 方法中将 message 显示</font></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TestMessageScheme</span> <span class=\"keyword\">implements</span> <span class=\"title\">Scheme</span> </span>{</div><div class=\"line\"></div><div class=\"line\">\t...</div><div class=\"line\">\t</div><div class=\"line\">\t<span class=\"annotation\">@Override</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> List&lt;Object&gt; <span class=\"title\">deserialize</span>(<span class=\"keyword\">byte</span>[] ser) {</div><div class=\"line\"></div><div class=\"line\">\t\tString msg;</div><div class=\"line\">\t\t<span class=\"keyword\">try</span> {</div><div class=\"line\">\t\t\tmsg = <span class=\"keyword\">new</span> String(ser, <span class=\"string\">\"UTF-8\"</span>);</div><div class=\"line\">\t\t\tSystem.out.println(<span class=\"string\">\"$$$$$$$$$$$$$$\"</span> + msg);</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">new</span> Values(msg);</div><div class=\"line\">\t\t} <span class=\"keyword\">catch</span> (UnsupportedEncodingException e) {</div><div class=\"line\">\t\t\tLOGGER.error(<span class=\"string\">\"Can not parse the provide message from bytes.\"</span>);</div><div class=\"line\">\t\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> RuntimeException(e);</div><div class=\"line\">\t\t}</div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<h3 id=\"编写_ShowKafkaMessageBolt\"><strong>编写 ShowKafkaMessageBolt</strong></h3>\n<ol>\n<li><font size=\"2\">在 prepare(Map, TopologyContext, OutputCollector) 中得到:OutputCollector(emit方法完成 message 的发射)、Context(提供 name/id 之类的属性)</font></li>\n<li><font size=\"2\">在 execute(Tuple) 中完成 message 处理工作</font></li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ShowKafkaMessageBolt</span> <span class=\"keyword\">implements</span> <span class=\"title\">IRichBolt</span> </span>{</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">private</span> OutputCollector collector;</div><div class=\"line\">\t<span class=\"keyword\">private</span> String name;</div><div class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">int</span> id;</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"annotation\">@SuppressWarnings</span>(<span class=\"string\">\"rawtypes\"</span>)</div><div class=\"line\">\t<span class=\"annotation\">@Override</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">prepare</span>(Map stormConf, TopologyContext context,</div><div class=\"line\">\t\t\tOutputCollector collector) {</div><div class=\"line\">\t\t<span class=\"keyword\">this</span>.collector = collector;</div><div class=\"line\">\t\t<span class=\"keyword\">this</span>.name = context.getThisComponentId();</div><div class=\"line\">\t\t<span class=\"keyword\">this</span>.id = context.getThisTaskId();</div><div class=\"line\">\t\tSystem.out.println(<span class=\"string\">\"Bolt: \"</span> + name + <span class=\"string\">\" and Id: \"</span> + id</div><div class=\"line\">\t\t\t\t+ <span class=\"string\">\" prepared ##################\"</span>);</div><div class=\"line\"></div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"annotation\">@Override</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">execute</span>(Tuple input) {</div><div class=\"line\"></div><div class=\"line\">\t\t<span class=\"keyword\">if</span> (input != <span class=\"keyword\">null</span>) {</div><div class=\"line\">\t\t\tString message = input.getString(<span class=\"number\">0</span>);</div><div class=\"line\">\t\t\tcollector.emit(<span class=\"keyword\">new</span> Values(message));</div><div class=\"line\">\t\t\tSystem.out.println(message);</div><div class=\"line\">\t\t}</div><div class=\"line\"></div><div class=\"line\">\t\tcollector.ack(input);</div><div class=\"line\"></div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<h3 id=\"编写_BehaviourAnalyse\"><strong>编写 BehaviourAnalyse</strong></h3>\n<ol>\n<li>基于 zookeeper属性 定义 Broker</li>\n<li>整合 broker、topic、zkRoot、spoutId 和 TestMessageScheme 为 SpoutConfig，完成 KafkaSpout 的实例化</li>\n<li>利用 LocalCluster 完成 topology 的提交</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BehaviourAnalyse</span> </span>{</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span>(String[] args) {</div><div class=\"line\"></div><div class=\"line\">\t\tBrokerHosts brokerHosts = <span class=\"keyword\">new</span> ZkHosts(<span class=\"string\">\"192.168.1.201:2181\"</span>);</div><div class=\"line\"></div><div class=\"line\">\t\tString topic = <span class=\"string\">\"my-replicated-topic\"</span>;</div><div class=\"line\"></div><div class=\"line\">\t\t<span class=\"javadoc\">/**</span></div><div class=\"line\">\t\t * We can get the param from the 'config/zookeeper.properties' path.&lt;BR&gt;</div><div class=\"line\">\t\t * # the directory where the snapshot is stored.&lt;BR&gt;</div><div class=\"line\">\t\t * dataDir=/tmp/zookeeper</div><div class=\"line\">\t\t */</div><div class=\"line\">\t\tString zkRoot = <span class=\"string\">\"/tmp/zookeeper\"</span>;</div><div class=\"line\">\t\tString spoutId = <span class=\"string\">\"myKafka\"</span>;</div><div class=\"line\"></div><div class=\"line\">\t\tSpoutConfig spoutConfig = <span class=\"keyword\">new</span> SpoutConfig(brokerHosts, topic, zkRoot,</div><div class=\"line\">\t\t\t\tspoutId);</div><div class=\"line\">\t\tspoutConfig.scheme = <span class=\"keyword\">new</span> SchemeAsMultiScheme(<span class=\"keyword\">new</span> TestMessageScheme());</div><div class=\"line\"></div><div class=\"line\">\t\tTopologyBuilder builder = <span class=\"keyword\">new</span> TopologyBuilder();</div><div class=\"line\">\t\tKafkaSpout kafkaSpout = <span class=\"keyword\">new</span> KafkaSpout(spoutConfig);</div><div class=\"line\">\t\tbuilder.setSpout(<span class=\"string\">\"kafka-spout\"</span>, kafkaSpout);</div><div class=\"line\"></div><div class=\"line\">\t\tbuilder.setBolt(<span class=\"string\">\"show-message-bolt\"</span>, <span class=\"keyword\">new</span> ShowKafkaMessageBolt())</div><div class=\"line\">\t\t\t\t.shuffleGrouping(<span class=\"string\">\"kafka-spout\"</span>);</div><div class=\"line\"></div><div class=\"line\">\t\tConfig conf = <span class=\"keyword\">new</span> Config();</div><div class=\"line\">\t\tconf.setDebug(<span class=\"keyword\">true</span>);</div><div class=\"line\">\t\tconf.put(Config.TOPOLOGY_MAX_SPOUT_PENDING, <span class=\"number\">1</span>);</div><div class=\"line\"></div><div class=\"line\">\t\tLocalCluster cluster = <span class=\"keyword\">new</span> LocalCluster();</div><div class=\"line\">\t\tcluster.submitTopology(<span class=\"string\">\"Show-Message-From-Kafka\"</span>, conf,</div><div class=\"line\">\t\t\t\tbuilder.createTopology());</div><div class=\"line\"></div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<h3 id=\"run_the_main_method-1\"><strong>run the main method</strong></h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">com.yuzhouwan.hadoop.customer_behaviour_analyse.BehaviourAnalyse</div></pre></td></tr></table></figure>\n\n<h3 id=\"start_a_kafka’s_producer\"><strong>start a kafka’s producer</strong></h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">bin/kafka-console-producer.<span class=\"keyword\">sh</span> --broker-<span class=\"keyword\">list</span> localhos<span class=\"variable\">t:9092</span> --topic my-replicated-topic</div></pre></td></tr></table></figure>\n\n<p>Input a sentence ending, like:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">This <span class=\"keyword\">is</span> a message <span class=\"keyword\">from</span> kafka.</div></pre></td></tr></table></figure>\n\n<p>You will see the information that be show in console sucessfully :-)</p>\n<h2 id=\"Storm_和_Kafka_双向整合已经完成\"><strong><font color=\"blue\"><em>Storm 和 Kafka 双向整合已经完成</em></font></strong></h2>\n<p>完全的整合，及其运用，见 <a href=\"https://github.com/MasteringStorm/shopping-web-site\" target=\"_blank\" rel=\"external\">here</a></p>\n<h2 id=\"小技巧\"><strong><font color=\"blue\"><em>小技巧</em></font></strong></h2>\n<h3 id=\"get_the_value_of_metadata-broker-list\"><strong>get the value of metadata.broker.list</strong></h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">vim</span> config/producer.properties</div></pre></td></tr></table></figure>\n\n<h3 id=\"查看_storm_与其他框架的支持与否\">查看 storm 与其他框架的支持与否</h3>\n<p><a href=\"http://mvnrepository.com/artifact/org.apache.storm\" target=\"_blank\" rel=\"external\">http://mvnrepository.com/artifact/org.apache.storm</a></p>\n<p><font size=\"2\"><strong><em><a href=\"https://github.com/MasteringStorm/customer-haviour-analyse\" target=\"_blank\" rel=\"external\">[Source]</a></em></strong></font></p>\n","source":"_posts/Storm-与-Kafka-的整合之三：Combination.md","raw":"title: Storm 与 Kafka 的整合之三：Combination\ndate: 2015-05-10 14:28:08\ntags:\n - Storm\n - Kafka\ncategories:\n - Storm\n - Kafka\n\n---\n\n\n## __<font color='blue'>*搭建 Storm 和 Kafka 的基础环境*__\n### __搭建 [Storm][1] 集群 (本地模式)__\n### __搭建 [Kafka][2] 环境__\n### __启动 Kafka__\n\n#### - start the zookeeper and kafka server\n```shell\n\tbin/zookeeper-server-start.sh config/zookeeper.properties\n```\n```shell\n\tbin/kafka-server-start.sh config/server.properties\n```\n\n#### - create a topic\n```shell\n\tbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic my-replicated-topic\n```\n<font size=2>&nbsp;&nbsp;&nbsp;&nbsp;We can now see that topic if we run the list topic command:\n```shell\n\tbin/kafka-topics.sh --list --zookeeper localhost:2181\n```\n\n## __<font color='blue'>*发送 Message 往 Kafka*__\n### __编写 SendMessageToKafka__\n1. <font size=2> 根据 kafka 中 cluster 的属性，定义好 Producer\n2. <font size=2> 利用 Producer.send(KeyedMessage) 方法，将 \"topic - message\" 发送给 Kafka\n\n```java\npublic class SendMessageToKafka {\n\n\tprivate static Producer<String, String> producer;\n\n\tprivate static void init() {\n\t\tProperties props = new Properties();\n\t\tprops.put(\"zk.connect\", \"192.168.1.201:2181\");\n\t\tprops.put(\"serializer.class\", \"kafka.serializer.StringEncoder\");\n\t\tprops.put(\"metadata.broker.list\", \"192.168.1.201:9092\");\n\t\tProducerConfig config = new ProducerConfig(props);\n\t\tproducer = new Producer<String, String>(config);\n\t}\n\n\tpublic static void main(String... arg) {\n\n\t\tinit();\n\n\t\tKeyedMessage<String, String> data = new KeyedMessage<String, String>(\n\t\t\t\t\"my-replicated-topic\", \"asdf2015\");\n\t\tproducer.send(data);\n\t\tproducer.close();\n\n\t}\n\n}\n```\n\n### __run the main method__\n```java\n\tcom.yuzhouwan.hadoop.customer_behaviour_analyse.kafka.SendMessageToKafka\n```\n\n### __check out the message that tht broker catched__\n```shell\n\tbin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic\n```\nThen, u will see that the 'asdf2015' message was sent sucessfully.\n\n\n## __<font color='blue'>*从 Kafka 中获得 Message*__\n### __编写 TestMessageScheme__\n<font size=2> 在 deserialize(byte[]) 方法中将 message 显示\n```java\npublic class TestMessageScheme implements Scheme {\n\n\t...\n\t\n\t@Override\n\tpublic List<Object> deserialize(byte[] ser) {\n\n\t\tString msg;\n\t\ttry {\n\t\t\tmsg = new String(ser, \"UTF-8\");\n\t\t\tSystem.out.println(\"$$$$$$$$$$$$$$\" + msg);\n\t\t\treturn new Values(msg);\n\t\t} catch (UnsupportedEncodingException e) {\n\t\t\tLOGGER.error(\"Can not parse the provide message from bytes.\");\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t...\n\n}\n```\n\n### __编写 ShowKafkaMessageBolt__\n1. <font size=2>在 prepare(Map, TopologyContext, OutputCollector) 中得到:OutputCollector(emit方法完成 message 的发射)、Context(提供 name/id 之类的属性)\n2. <font size=2>在 execute(Tuple) 中完成 message 处理工作\n```java\npublic class ShowKafkaMessageBolt implements IRichBolt {\n\n\tprivate OutputCollector collector;\n\tprivate String name;\n\tprivate int id;\n\n\t@SuppressWarnings(\"rawtypes\")\n\t@Override\n\tpublic void prepare(Map stormConf, TopologyContext context,\n\t\t\tOutputCollector collector) {\n\t\tthis.collector = collector;\n\t\tthis.name = context.getThisComponentId();\n\t\tthis.id = context.getThisTaskId();\n\t\tSystem.out.println(\"Bolt: \" + name + \" and Id: \" + id\n\t\t\t\t+ \" prepared ##################\");\n\n\t}\n\n\t@Override\n\tpublic void execute(Tuple input) {\n\n\t\tif (input != null) {\n\t\t\tString message = input.getString(0);\n\t\t\tcollector.emit(new Values(message));\n\t\t\tSystem.out.println(message);\n\t\t}\n\n\t\tcollector.ack(input);\n\n\t}\n\n\t...\n\n}\n```\n\n### __编写 BehaviourAnalyse__\n1. 基于 zookeeper属性 定义 Broker\n2. 整合 broker、topic、zkRoot、spoutId 和 TestMessageScheme 为 SpoutConfig，完成 KafkaSpout 的实例化\n3. 利用 LocalCluster 完成 topology 的提交\n```java\npublic class BehaviourAnalyse {\n\n\tpublic static void main(String[] args) {\n\n\t\tBrokerHosts brokerHosts = new ZkHosts(\"192.168.1.201:2181\");\n\n\t\tString topic = \"my-replicated-topic\";\n\n\t\t/**\n\t\t * We can get the param from the 'config/zookeeper.properties' path.<BR>\n\t\t * # the directory where the snapshot is stored.<BR>\n\t\t * dataDir=/tmp/zookeeper\n\t\t */\n\t\tString zkRoot = \"/tmp/zookeeper\";\n\t\tString spoutId = \"myKafka\";\n\n\t\tSpoutConfig spoutConfig = new SpoutConfig(brokerHosts, topic, zkRoot,\n\t\t\t\tspoutId);\n\t\tspoutConfig.scheme = new SchemeAsMultiScheme(new TestMessageScheme());\n\n\t\tTopologyBuilder builder = new TopologyBuilder();\n\t\tKafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);\n\t\tbuilder.setSpout(\"kafka-spout\", kafkaSpout);\n\n\t\tbuilder.setBolt(\"show-message-bolt\", new ShowKafkaMessageBolt())\n\t\t\t\t.shuffleGrouping(\"kafka-spout\");\n\n\t\tConfig conf = new Config();\n\t\tconf.setDebug(true);\n\t\tconf.put(Config.TOPOLOGY_MAX_SPOUT_PENDING, 1);\n\n\t\tLocalCluster cluster = new LocalCluster();\n\t\tcluster.submitTopology(\"Show-Message-From-Kafka\", conf,\n\t\t\t\tbuilder.createTopology());\n\n\t}\n\n}\n```\n\n### __run the main method__\n```java\n\tcom.yuzhouwan.hadoop.customer_behaviour_analyse.BehaviourAnalyse\n```\n\n### __start a kafka's producer__\n```shell\n\tbin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic\n```\nInput a sentence ending, like:\n```shell\n\tThis is a message from kafka.\n```\nYou will see the information that be show in console sucessfully :-)\n\n\n## __<font color='blue'>*Storm 和 Kafka 双向整合已经完成*__\n完全的整合，及其运用，见 [here][4]\n\n\n## __<font color='blue'>*小技巧*__\n### __get the value of metadata.broker.list__\n```shell\n\tvim config/producer.properties\n```\n\n### 查看 storm 与其他框架的支持与否\n[http://mvnrepository.com/artifact/org.apache.storm][3]\n\n<font size=2>__*[[Source]][5]*__\n\n[1]:http://storm.apache.org/documentation/Home.html\n[2]:http://kafka.apache.org/documentation.html\n[3]:http://mvnrepository.com/artifact/org.apache.storm\n[4]:https://github.com/MasteringStorm/shopping-web-site\n[5]:https://github.com/MasteringStorm/customer-haviour-analyse\n","slug":"Storm-与-Kafka-的整合之三：Combination","updated":1431245174000,"excerpt":"","_id":"keg97xozltugcohs","comments":true,"layout":"post","photos":[],"link":""},{"title":"Storm 与 Kafka 的整合之一：Storm","date":1429700982000,"tags":["jhce84bmw2q9nu7n","11cpxxkwjnfgt7bl"],"categories":["k8prskk4oioqqy4b"],"content":"<h2 id=\"什么是_Storm?\"><strong><font color=\"blue\"><em>什么是 Storm?</em></font></strong></h2>\n<p>&nbsp;&nbsp; <font size=\"3\"> Apache Storm is a free and open source distributed realtime computation system. - - <a href=\"https://storm.apache.org/\" target=\"_blank\" rel=\"external\">Official website</a></font></p>\n<h2 id=\"为什么要有_Storm?\"><strong><font color=\"blue\"><em>为什么要有 Storm?</em></font></strong></h2>\n<h3 id=\"分布式\">分布式</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">具备经济、快速、可靠、易扩充、数据共享、设备共享、通讯方便、灵活等分布式所具备的特性</div></pre></td></tr></table></figure>\n\n<h3 id=\"可扩展性\">可扩展性</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">计算在多线程、进程 和 服务器之间并行进行</div></pre></td></tr></table></figure>\n\n<h3 id=\"高可靠性\">高可靠性</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">能管理工作进程 和 节点的故障</div><div class=\"line\">消息处理，能得到一次完成处理的保证</div></pre></td></tr></table></figure>\n\n<h3 id=\"编程模型简单\">编程模型简单</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">降低了并行批处理复杂性</div></pre></td></tr></table></figure>\n\n<h3 id=\"高效实时\">高效实时</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">利用 ZeroMQ 保证了消息的快速处理</div></pre></td></tr></table></figure>\n\n<h3 id=\"支持热部署\">支持热部署</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">加速应用开发</div></pre></td></tr></table></figure>\n\n<h2 id=\"Storm_工作机制\"><strong><font color=\"blue\"><em>Storm 工作机制</em></font></strong></h2>\n<h3 id=\"一些主要概念\">一些主要概念</h3>\n<ul>\n<li>Topology（计算拓扑）</li>\n<li>Stream（消息流）</li>\n<li>Spout（消息源）</li>\n<li>Bolt（消息处理者）</li>\n<li>grouping（数据的分发方式）</li>\n<li>Topology（拓扑）</li>\n<li>Worker（工作进程）</li>\n<li>Task（执行具体逻辑的任务）</li>\n<li>Executor（执行 Task 的线程）</li>\n<li>Configuration（配置）</li>\n</ul>\n","source":"_posts/Storm-与-Kafka-的整合之一：Storm.md","raw":"title: Storm 与 Kafka 的整合之一：Storm\ndate: 2015-04-22 19:09:42\ntags:\n- Storm\n- Kafka\ncategories:\n- Storm\n---\n\n## __<font color='blue'>*什么是 Storm?*__\n\n&nbsp;&nbsp; <font size=3> Apache Storm is a free and open source distributed realtime computation system. - - [Official website][1]\n\n## __<font color='blue'>*为什么要有 Storm?*__\n###分布式\n```clojure\n\t具备经济、快速、可靠、易扩充、数据共享、设备共享、通讯方便、灵活等分布式所具备的特性\n```\n###可扩展性\n```clojure\n\t计算在多线程、进程 和 服务器之间并行进行\n```\n###高可靠性\n```clojure\n\t能管理工作进程 和 节点的故障\n\t消息处理，能得到一次完成处理的保证\n```\n###编程模型简单\n```clojure\n\t降低了并行批处理复杂性\n```\n###高效实时\n```clojure\n\t利用 ZeroMQ 保证了消息的快速处理\n```\n###支持热部署\n```clojure\n\t加速应用开发\n```\n\n## __<font color='blue'>*Storm 工作机制*__\n### 一些主要概念\n - Topology（计算拓扑）\n - Stream（消息流）\n - Spout（消息源）\n - Bolt（消息处理者）\n -  grouping（数据的分发方式）\n - Topology（拓扑）\n - Worker（工作进程）\n - Task（执行具体逻辑的任务）\n - Executor（执行 Task 的线程）\n - Configuration（配置）\n\n\n[1]:https://storm.apache.org/\n","slug":"Storm-与-Kafka-的整合之一：Storm","updated":1429872749000,"excerpt":"","_id":"9zrz1hse4e1drwhv","comments":true,"layout":"post","photos":[],"link":""},{"title":"Storm 与 Kafka 的整合之二：Kafka","date":1431233022000,"tags":["jhce84bmw2q9nu7n","11cpxxkwjnfgt7bl"],"categories":["v7znvkc3c0heesni"],"content":"<h2 id=\"什么是_Kafka?\"><strong><font color=\"blue\"><em>什么是 Kafka?</em></font></strong></h2>\n<p>&nbsp;&nbsp; <font size=\"3\"> Kafka is a distributed, partitioned, replicated commit log service. It provides the functionality of a messaging system, but with a unique design. - - <a href=\"https://kafka.apache.org/\" target=\"_blank\" rel=\"external\">Official website</a></font></p>\n<h2 id=\"为什么要有_Kafka?\"><strong><font color=\"blue\"><em>为什么要有 Kafka?</em></font></strong></h2>\n<h3 id=\"分布式\">分布式</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">具备经济、快速、可靠、易扩充、数据共享、设备共享、通讯方便、灵活等分布式所具备的特性</div></pre></td></tr></table></figure>\n\n<h3 id=\"高吞吐量\">高吞吐量</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">同时为发布者和订阅者提高吞吐量</div></pre></td></tr></table></figure>\n\n<h3 id=\"高可靠性\">高可靠性</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">支持多个订阅者，当订阅失败的时候，能够自动均衡订阅者</div></pre></td></tr></table></figure>\n\n<h3 id=\"离线_&amp;_实时性\">离线 &amp; 实时性</h3>\n<figure class=\"highlight clojure\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">能将消息持久化，进行批量处理</div></pre></td></tr></table></figure>\n\n<h2 id=\"Kafka_工作机制\"><strong><font color=\"blue\"><em>Kafka 工作机制</em></font></strong></h2>\n<h3 id=\"一些主要概念\">一些主要概念</h3>\n<ul>\n<li>Topic（主题）</li>\n</ul>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">A topic is a category or feed name to which messages are published.</div></pre></td></tr></table></figure>\n\n<ul>\n<li>Producers（发布者）</li>\n</ul>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">Producers publish data to the topics of their choice. The producer is responsible <span class=\"keyword\">for</span> choosing which message to assign to which partition within the topic.</div></pre></td></tr></table></figure>\n\n<ul>\n<li>Consumers（订阅者）</li>\n</ul>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">Messaging traditionally has two models: queuing and publish-subscribe. </div><div class=\"line\">In a queue, a pool of consumers may read from a server and each message goes to one of them; </div><div class=\"line\">in publish-subscribe the message is broadcast to all consumers.</div></pre></td></tr></table></figure>\n\n<h3 id=\"示意图\">示意图</h3>\n<p><img src=\"/../2015-5-10/kafka.png\" alt=\"\"></p>\n","source":"_posts/Storm-与-Kafka-的整合之二：Kafka.md","raw":"title: Storm 与 Kafka 的整合之二：Kafka\ndate: 2015-05-10 12:43:42\ntags:\n- Storm\n- Kafka\ncategories:\n- Kafka\n---\n\n## __<font color='blue'>*什么是 Kafka?*__\n\n&nbsp;&nbsp; <font size=3> Kafka is a distributed, partitioned, replicated commit log service. It provides the functionality of a messaging system, but with a unique design. - - [Official website][1]\n\n## __<font color='blue'>*为什么要有 Kafka?*__\n###分布式\n```clojure\n\t具备经济、快速、可靠、易扩充、数据共享、设备共享、通讯方便、灵活等分布式所具备的特性\n```\n###高吞吐量\n```clojure\n\t同时为发布者和订阅者提高吞吐量\n```\n###高可靠性\n```clojure\n\t支持多个订阅者，当订阅失败的时候，能够自动均衡订阅者\n```\n###离线 & 实时性\n```clojure\n\t能将消息持久化，进行批量处理\n```\n\n## __<font color='blue'>*Kafka 工作机制*__\n### 一些主要概念\n - Topic（主题）\n```scala\n\tA topic is a category or feed name to which messages are published.\n```\n\n - Producers（发布者）\n```scala\n\tProducers publish data to the topics of their choice. The producer is responsible for choosing which message to assign to which partition within the topic.\n```\n\n - Consumers（订阅者）\n```scala\n\tMessaging traditionally has two models: queuing and publish-subscribe. \n\tIn a queue, a pool of consumers may read from a server and each message goes to one of them; \n\tin publish-subscribe the message is broadcast to all consumers.\n```\n\n### 示意图\n![][2]\n\n[1]:https://kafka.apache.org/\n[2]:/../2015-5-10/kafka.png","slug":"Storm-与-Kafka-的整合之二：Kafka","updated":1439456683000,"excerpt":"","_id":"lz5zae3p0ex7sg0i","comments":true,"layout":"post","photos":[],"link":""},{"title":"What is the Node.js?","date":1414937318000,"tags":["bqus80m5xcxzaorh"],"categories":["ifi2x4menzkubm48"],"content":"<p>&nbsp;&nbsp;<em>Node.js® is a platform built on Chrome’s JavaScript runtime for easily building fast, scalable network applications. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices.</em></p>\n<p><strong>Current Version: v0.10.33</strong></p>\n<p>from <a href=\"http://www.nodejs.org\" target=\"_blank\" rel=\"external\">Node.js</a></p>\n","source":"_posts/What-is-the-Node-js.md","raw":"title: What is the Node.js?\ndate: 2014-11-02 22:08:38\ntags: \n- Node.js\ncategories: \n- Node.js\n---\n\n&nbsp;&nbsp;*Node.js® is a platform built on Chrome's JavaScript runtime for easily building fast, scalable network applications. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices.*\n\n**Current Version: v0.10.33**\n\nfrom [Node.js][1]\n\n[1]:http://www.nodejs.org\n","slug":"What-is-the-Node-js","updated":1414997690000,"excerpt":"","_id":"s9x4sgxklpdb0w6t","comments":true,"layout":"post","photos":[],"link":""},{"title":"asdf's Hexo Blog","date":1414800659000,"tags":["mut4rilgbnsjqb8w"],"categories":["yr9q5watou0iljwm"],"content":"<p>Welcome to my blog!</p>\n","source":"_posts/asdf-s-Hexo-Blog.md","raw":"title: \"asdf's Hexo Blog\"\ndate: 2014-11-01 08:10:59\ntags:\n- Hexo\ncategories:\n- Hexo\n---\n\nWelcome to my blog!\n","slug":"asdf-s-Hexo-Blog","updated":1416129181000,"excerpt":"","_id":"3ngs3hwwgl0vbull","comments":true,"layout":"post","photos":[],"link":""},{"title":"为什么 JavaScript 对服务端开发很重要?","date":1415068812000,"tags":["4zpt0iwnywnmec6s","7pj61lmo7g34jrwm","42trimtt5i9u08s5","bqus80m5xcxzaorh","ex2eqjipdeq9k9ys","1b2g27f5ujb6fr6e","un8oejz6uj4bd78d","yrpxq03flc7lvilg"],"categories":["yv4bf02ij6h9d5lx"],"content":"<h3 id=\"_开发人员用一种语言就能编写整个_Web_应用_\"><em><strong> 开发人员用一种语言就能编写整个 Web 应用 </strong></em></h3>\n<ul>\n<li>可以减少开发客户端和服务端时所需的语言切换(Clojure, <a href=\"https://github.com/clojure/clojurescript/\" target=\"_blank\" rel=\"external\">ClojureScript</a> 一样的道理)</li>\n<li>代码可以再客户端和服务端中共享(表单校验或游戏逻辑中使用同样的代码)</li>\n</ul>\n<h3 id=\"_JSON_是目前非常流行的数据交换格式_\"><em><strong> JSON 是目前非常流行的数据交换格式 </strong></em></h3>\n<ul>\n<li>json 还是 JavaScript 原生的</li>\n</ul>\n<h3 id=\"_有些_NOSQL_数据库中用的就是_JavaScript_语言_\"><em><strong> 有些 NOSQL 数据库中用的就是 JavaScript 语言 </strong></em></h3>\n<ul>\n<li>MongoDB 的管理和查询语言都是 JavaScript</li>\n<li>CouchDB 的 Map/reduce 也是 JavaScript</li>\n</ul>\n<h3 id=\"_JavaScript_是一门编译目标语言_\"><em><strong> JavaScript 是一门编译目标语言 </strong></em></h3>\n<ul>\n<li><a href=\"https://github.com/jashkenas/coffeescript/wiki/List-of-languages-that-compile-to-JS/\" target=\"_blank\" rel=\"external\">List of languages that compile to JS</a></li>\n</ul>\n<h3 id=\"_Node_用的虚拟机(V8)会紧跟_ECMAScirpt_标准_\"><em><strong> Node 用的虚拟机(V8)会紧跟 <a href=\"http://en.wikipedia.org/wiki/ECMAScript/\" target=\"_blank\" rel=\"external\">ECMAScirpt</a> 标准 </strong></em></h3>\n<ul>\n<li>在 Node 中如果想用新的 JavaScript 语言特性，不用等到所有浏览器都支持</li>\n</ul>\n","source":"_posts/为什么-JavaScript-对服务端开发很重要.md","raw":"title: 为什么 JavaScript 对服务端开发很重要?\ndate: 2014-11-04 10:40:12\ntags: \n- JavaScript\n- JSON\n- NOSQL\n- Node.js\n- ECMAScirpt\n- V8\n- Clojure\n- ClojureScript\ncategories: \n- JavaScript\n---\n\n###_** 开发人员用一种语言就能编写整个 Web 应用 **_\n* 可以减少开发客户端和服务端时所需的语言切换\\(Clojure, [ClojureScript][3] 一样的道理\\)\n* 代码可以再客户端和服务端中共享\\(表单校验或游戏逻辑中使用同样的代码\\)\n\n###_** JSON 是目前非常流行的数据交换格式 **_\n* json 还是 JavaScript 原生的\n\n###_** 有些 NOSQL 数据库中用的就是 JavaScript 语言 **_\n* MongoDB 的管理和查询语言都是 JavaScript\n* CouchDB 的 Map/reduce 也是 JavaScript\n\n###_** JavaScript 是一门编译目标语言 **_\n* [List of languages that compile to JS][1]\n\n###_** Node 用的虚拟机\\(V8\\)会紧跟 [ECMAScirpt][2] 标准 **_\n* 在 Node 中如果想用新的 JavaScript 语言特性，不用等到所有浏览器都支持\n\n[1]:https://github.com/jashkenas/coffeescript/wiki/List-of-languages-that-compile-to-JS/\n[2]:http://en.wikipedia.org/wiki/ECMAScript/\n[3]:https://github.com/clojure/clojurescript/\n","slug":"为什么-JavaScript-对服务端开发很重要","updated":1416130474000,"excerpt":"","_id":"lzq1z1qvh0t5lofq","comments":true,"layout":"post","photos":[],"link":""},{"title":"散列表","date":1418475300000,"tags":["kt41z32ienkpakht","5f6v0je6qudesw6s","z9aixi8437i6grje"],"categories":["tsa5gxf1bo63eiuj","ka9ae04rqkmpo6yw"],"content":"<h2 id=\"_什么是_散列表?\"><strong> <font color=\"blue\"> <em>什么是 散列表?</em></font></strong></h2>\n<p>&nbsp;&nbsp; <font size=\"3\"> 散列表（Hash table, 也叫哈希表）是根据关键码值 (Key value) 而直接进行访问的数据结构。也就是说, 它通过把关键码值映射到表中一个位置来访问记录, 以加快查找的速度。这个映射函数叫做散列函数, 存放记录的数组叫做散列表。 - - <a href=\"http://baike.baidu.com/link?url=kMtqNs5r1u9kIx4w6yBze9lTiitzfFsk2jUNvjW4lJ7zXNYTUSp0rXq8kwW9t0l-mv2eEzA47GYUyUGfoSS3x\" target=\"_blank\" rel=\"external\">百度百科</a></font></p>\n<h2 id=\"_为什么要有_散列表?\"><strong> <font color=\"blue\"> <em>为什么要有 散列表?</em></font></strong></h2>\n<h3 id=\"可以提供快速的插入操作和查找操作\"><strong>可以提供快速的插入操作和查找操作</strong></h3>\n<p>&nbsp;&nbsp; <font size=\"3\"> 不论哈希表中有多少数据, 插入和删除（有时包括侧除）只需要接近常量的时间即 O(1) 的时间级<br>&nbsp;&nbsp; <font size=\"3\"> 实际上, 这只需要几条机器指令<br>&nbsp;&nbsp; <font size=\"3\"> 哈希表运算得非常快, 在计算机程序中, 如果需要在一秒种内查找上千条记录通常使用哈希表 （例如拼写检查器）（树的操作通常需要 O(N) 的时间级）</font></font></font></p>\n<h3 id=\"编程实现相对容易\"><strong>编程实现相对容易</strong></h3>\n<h2 id=\"_散列表工作机制\"><strong> <font color=\"blue\"> <em>散列表工作机制</em></font></strong></h2>\n<h3 id=\"存储\"><strong>存储</strong></h3>\n<p>&nbsp;&nbsp; <font size=\"3\"> 使用一个数组实现的无序符号表<br>&nbsp;&nbsp; <font size=\"3\"> 意味着, 数组创建后, 难于扩展（某些哈希表被基本填满时, 性能下降得非常严重）<br>&nbsp;&nbsp; <font size=\"3\"> 要么预设足够的空间, 要么定期将数据迁移到更大的哈希表</font></font></font></p>\n<h3 id=\"查找\"><strong>查找</strong></h3>\n<p>&nbsp;&nbsp; <font size=\"3\"> 首先, 用散列函数将被查找的键转化为数组的一个索引<br>&nbsp;&nbsp; <font size=\"3\"> 其次, 处理碰撞冲突</font></font></p>\n<ul>\n<li>拉链法<br>&nbsp;&nbsp; <font size=\"3\"> 1. 使用原始的链表数据类型来扩展 SequentialSerchT<br>&nbsp;&nbsp; <font size=\"3\"> 2. 为 M 个元素分别构建符号表来保存散列到这里的键</font></font></li>\n<li>线性探测法<br>&nbsp;&nbsp; <font size=\"3\"> 用大小为 M 的数组保存 N 个键值对（M &gt; N, 依靠数组中空位解决碰撞冲突, 此策略的所有方法统称为开放地址散列表） </font></li>\n</ul>\n<h2 id=\"_散列表在_Java_中的相关实现_:_HashMap\"><strong> <font color=\"blue\"> <em>散列表在 Java 中的相关实现 : HashMap</em></font></strong></h2>\n<h3 id=\"java-lang-Object_的规范\"><strong>java.lang.Object 的规范</strong></h3>\n<ol>\n<li>如果一个对象的 equals 方法做比较所用到的信息没有被修改的话, 那么, 对该对象调用 hashCode 方法多次, 必须始终如一地返回同一个整数</li>\n<li>如果两个对象根据 equals (Object) 方法是相等, 那么调用这两个对象中任意一个对象的 hashCode 方法必须产生同样的整数结果</li>\n<li>对于不相等的对象产生截然不同的整数结果, 有可能提高散列表 (hash table) 的性能</li>\n</ol>\n<h3 id=\"HashMap_失效的情况\"><strong>HashMap 失效的情况</strong></h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">package</span> com.yuzhouwan.hashCode2;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> java.util.HashMap;</div><div class=\"line\"><span class=\"keyword\">import</span> java.util.Map;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PhoneNumber</span> </span>{</div><div class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">short</span> areaCode;</div><div class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">short</span> exchange;</div><div class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">short</span> extension;</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"title\">PhoneNumber</span>(<span class=\"keyword\">int</span> areaCode, <span class=\"keyword\">int</span> exchange, <span class=\"keyword\">int</span> extension) {</div><div class=\"line\">\t\trangeCheck(areaCode, <span class=\"number\">999</span>, <span class=\"string\">\"area code\"</span>);</div><div class=\"line\">\t\trangeCheck(exchange, <span class=\"number\">999</span>, <span class=\"string\">\"exchange\"</span>);</div><div class=\"line\">\t\trangeCheck(extension, <span class=\"number\">9999</span>, <span class=\"string\">\"extension\"</span>);</div><div class=\"line\">\t\t<span class=\"keyword\">this</span>.areaCode = (<span class=\"keyword\">short</span>) areaCode;</div><div class=\"line\">\t\t<span class=\"keyword\">this</span>.exchange = (<span class=\"keyword\">short</span>) exchange;</div><div class=\"line\">\t\t<span class=\"keyword\">this</span>.extension = (<span class=\"keyword\">short</span>) extension;</div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">rangeCheck</span>(<span class=\"keyword\">int</span> arg, <span class=\"keyword\">int</span> max, String name) {</div><div class=\"line\">\t\t<span class=\"keyword\">if</span> (arg &lt; <span class=\"number\">0</span> || arg &gt; max)</div><div class=\"line\">\t\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(name + <span class=\"string\">\": \"</span> + arg);</div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"annotation\">@Override</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">hashCode</span>() {</div><div class=\"line\">\t\t<span class=\"keyword\">final</span> <span class=\"keyword\">int</span> prime = <span class=\"number\">31</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> result = <span class=\"number\">1</span>;</div><div class=\"line\">\t\tresult = prime * result + areaCode;</div><div class=\"line\">\t\tresult = prime * result + exchange;</div><div class=\"line\">\t\tresult = prime * result + extension;</div><div class=\"line\">\t\t<span class=\"keyword\">return</span> result;</div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"javadoc\">/**</span></div><div class=\"line\">\t * If u put the param that is not Object and forget use the annotation that name is 'Override', </div><div class=\"line\">\t * the equals method loses efficacy and u will find the reason hardly.</div><div class=\"line\">\t */</div><div class=\"line\">\t<span class=\"annotation\">@Override</span></div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">equals</span>(Object o) {</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(o == <span class=\"keyword\">this</span>)</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(!(o <span class=\"keyword\">instanceof</span> PhoneNumber))</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</div><div class=\"line\">\t\tPhoneNumber pn = (PhoneNumber)o;</div><div class=\"line\">\t\t<span class=\"keyword\">return</span> pn.extension == extension && </div><div class=\"line\">\t\t\tpn.exchange == exchange && </div><div class=\"line\">\t\t\tpn.areaCode == areaCode;</div><div class=\"line\">\t}</div><div class=\"line\">\t</div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">equals2</span>(Object obj) {</div><div class=\"line\">\t\t<span class=\"keyword\">if</span> (<span class=\"keyword\">this</span> == obj)</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span> (obj == <span class=\"keyword\">null</span>)</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span> (getClass() != obj.getClass())</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</div><div class=\"line\">\t\tPhoneNumber other = (PhoneNumber) obj;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span> (areaCode != other.areaCode)</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span> (exchange != other.exchange)</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span> (extension != other.extension)</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</div><div class=\"line\">\t}</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"javadoc\">/**</span></div><div class=\"line\">\t * if u do not rewrite the hashCode method, </div><div class=\"line\">\t * u will get the different hashCode when u init the same object, then the hashMap will work unusually.</div><div class=\"line\">\t */</div><div class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span>(String... args) {</div><div class=\"line\">\t\tMap&lt;PhoneNumber, String&gt; m = <span class=\"keyword\">new</span> HashMap&lt;PhoneNumber, String&gt;();</div><div class=\"line\"></div><div class=\"line\">\t\tPhoneNumber pn = <span class=\"keyword\">new</span> PhoneNumber(<span class=\"number\">408</span>, <span class=\"number\">867</span>, <span class=\"number\">5309</span>);</div><div class=\"line\">\t\tm.put(pn, <span class=\"string\">\"Jenny\"</span>);</div><div class=\"line\"></div><div class=\"line\">\t\tSystem.out.println(<span class=\"string\">\"pn\\' hashCode: \"</span> + pn.hashCode() + <span class=\"string\">\" - \"</span></div><div class=\"line\">\t\t\t\t+ m.get(pn));</div><div class=\"line\"></div><div class=\"line\">\t\tpn = <span class=\"keyword\">new</span> PhoneNumber(<span class=\"number\">408</span>, <span class=\"number\">867</span>, <span class=\"number\">5309</span>);</div><div class=\"line\">\t\tSystem.out.println(<span class=\"string\">\"pn\\' hashCode: \"</span> + pn.hashCode() + <span class=\"string\">\" - \"</span></div><div class=\"line\">\t\t\t\t+ m.get(pn));</div><div class=\"line\">\t}</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"3\"> 如果没有 hashCode 的结果：</font></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">pn' hashCode: 909751202 - Jenny</div><div class=\"line\">pn' hashCode: 104885374 - null</div></pre></td></tr></table></figure>\n\n<h3 id=\"处方\"><strong>处方</strong></h3>\n<ol>\n<li>把某个非零长数值, 比如说 17, 保存在一个叫 result 的 int 类型变量中</li>\n<li>对于对象中每一个关键域 f（指 equals 方法中考虑的每个域）, 完成以下步骤：<br> a.为该域计算 int 类型的散列码 c：<pre><code> i.    如果该域是 <span class=\"keyword\">boolean</span> 类型, 则计算 (f?<span class=\"number\">0</span>:<span class=\"number\">1</span>) \n ii.    如果该域是 <span class=\"keyword\">byte</span>、<span class=\"keyword\">char</span>、<span class=\"keyword\">short</span> 或者 <span class=\"keyword\">int</span> 类型, 则计算  (<span class=\"keyword\">int</span>) f\n iii.    如果该域是 <span class=\"keyword\">long</span> 类型, 则计算  (<span class=\"keyword\">int</span>)  (f ^  (f &gt;&gt;&gt; <span class=\"number\">32</span>) ) \n iv.    如果该域是 <span class=\"keyword\">float</span> 类型, 则计算 <span class=\"keyword\">Float</span>.floatToIntBits (f) \n v.    如果该域是 <span class=\"keyword\">double</span> 类型, 则计算 <span class=\"keyword\">Double</span>.doubleToLongBits (f) 得到一个 <span class=\"keyword\">long</span> 类型的值, 然后按照步骤 <span class=\"number\">2</span>.a.iii, 对该 <span class=\"keyword\">long</span> 型值计算散列值\n vi.    如果该域是一个对象引用, 并且该类的 equals 方法通过递归调用 equals 的方式来比较这个域, 则同样对这个域递归调用 hashCode。\n     如果要求一个更为复杂的比较, 则为这个域计算一个 <span class=\"string\">\"规范表示 (canonical representation)\"</span>, 然后针对这个范式表示调用 hashCode。\n     如果这个域的值为 <span class=\"keyword\">null</span>, 则返回 <span class=\"number\">0</span> (这货其他某个常数, 但习惯上使用 <span class=\"number\">0</span>) \n vii.    如果该域是一个数组, 则把每一个元素当做单独的域来处理。\n     也就是说, 递归地应用上述规则, 对每个重要的元素计算一个散列码, 然后根据步骤 <span class=\"number\">2</span>.b 中的做法把这些散列值组合起来\n</code></pre> b.按照下面的公式, 把步骤 a 中计算得到的散列码 c 组合到 result 中：<pre><code> <span class=\"literal\">result</span> = <span class=\"number\">37</span> * <span class=\"literal\">result</span> + c;\n</code></pre></li>\n<li>返回 result</li>\n<li>写完了 hashCode 方法之后, 问自己 “是否相等的实例具有相等的散列码” 。如果不是的话, 找出原因, 并修改错误。</li>\n</ol>\n<h3 id=\"冗余域_(redundant_field)\"><strong>冗余域 (redundant field)</strong></h3>\n<p>&nbsp;&nbsp; <font size=\"3\"> 如果一个域的值可以根据参与计算的其他域值计算出来, 则把这样的域排除在外是可以接受的。</font></p>\n<h2 id=\"_ConcurrentHashMap_如何实现线程安全\"><strong> <font color=\"blue\"> <em>ConcurrentHashMap 如何实现线程安全</em></font></strong></h2>\n<h3 id=\"ConcurrentHashMap_中加了_lock_的方法_&nbsp;_(scanAndLockForPut、scanAndLock、lock_用来添加锁,_并使用_try-finally_释放锁,_以及使用_sun-misc-Unsafe_提供_volatile_变量)\">ConcurrentHashMap 中加了 lock 的方法 &nbsp; <font size=\"3\"> <strong><em>(scanAndLockForPut、scanAndLock、lock 用来添加锁, 并使用 try-finally 释放锁, 以及使用 sun.misc.Unsafe 提供 volatile 变量)</em></strong></font></h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">+ java.util.concurrent.ConcurrentHashMap.Segment&lt;K, V&gt;</div><div class=\"line\"></div><div class=\"line\">\t- scanAndLockForPut\t+\tunclock</div><div class=\"line\">\t\tput</div><div class=\"line\">\t- scanAndLock\t\t+\tunclock</div><div class=\"line\">\t\tremove、replace</div><div class=\"line\">\t- lock\t\t\t+\tunclock</div><div class=\"line\">\t\tclear</div><div class=\"line\">\t- java.util.concurrent.locks.ReentrantLock.lock()\t+ unlock()</div><div class=\"line\">\t\tsize、containsValue</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">+ java.util.concurrent.locks.ReentrantLock.lock() -&gt; java.util.concurrent.locks.ReentrantLock.Sync.lock()</div><div class=\"line\">+ java.util.concurrent.locks.ReentrantLock.unlock() -&gt; java.util.concurrent.locks.AbstractQueuedSynchronizer.release(<span class=\"keyword\">int</span>)</div><div class=\"line\"></div><div class=\"line\">\twriteObject(Serialization Support)</div></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"sun-misc-Unsafe-getObjectVolatile(Object,_long)\">sun.misc.Unsafe.getObjectVolatile(Object, long)</h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">get\t\t\t<span class=\"comment\">// manually integrate access methods to reduce overhead</span></div><div class=\"line\">containsKey\t\t<span class=\"comment\">// same as get() except no need for volatile value read</span></div></pre></td></tr></table></figure>\n\n<h3 id=\"readObject_中读取流中所有的_Object（小技巧）\">readObject 中读取流中所有的 Object<strong><em>（小技巧）</em></strong></h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Read the keys and values, and put the mappings in the table</span></div><div class=\"line\"><span class=\"keyword\">for</span> (;;) {\t\t\t\t\t\t<span class=\"comment\">// = while(true)</span></div><div class=\"line\">    K key = (K) s.readObject();\t\t\t\t<span class=\"comment\">//java.io.ObjectInputStream</span></div><div class=\"line\">    V value = (V) s.readObject();</div><div class=\"line\">    <span class=\"keyword\">if</span> (key == <span class=\"keyword\">null</span>)</div><div class=\"line\">        <span class=\"keyword\">break</span>;\t\t\t\t\t\t<span class=\"comment\">//只有达到这个条件, 才可以退出这个死循环</span></div><div class=\"line\">    put(key, value);</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n","source":"_posts/散列表.md","raw":"title: 散列表\ndate: 2014-12-13 20:55:00\ntags:\n- HashMap\n- Hash\n- ConcurrentHashMap\ncategories:\n- HashMap\n- ConcurrentHashMap\n---\n\n##__ <font color='blue'> *什么是 散列表?*__\n&nbsp;&nbsp; <font size=3> 散列表（Hash table, 也叫哈希表）是根据关键码值 (Key value) 而直接进行访问的数据结构。也就是说, 它通过把关键码值映射到表中一个位置来访问记录, 以加快查找的速度。这个映射函数叫做散列函数, 存放记录的数组叫做散列表。 - - [百度百科][1]\n\n##__ <font color='blue'> *为什么要有 散列表?*__\n###**可以提供快速的插入操作和查找操作**\n&nbsp;&nbsp; <font size=3> 不论哈希表中有多少数据, 插入和删除（有时包括侧除）只需要接近常量的时间即 O(1) 的时间级\n&nbsp;&nbsp; <font size=3> 实际上, 这只需要几条机器指令\n&nbsp;&nbsp; <font size=3> 哈希表运算得非常快, 在计算机程序中, 如果需要在一秒种内查找上千条记录通常使用哈希表 （例如拼写检查器）（树的操作通常需要 O(N) 的时间级）\n\n###**编程实现相对容易**\n\n##__ <font color='blue'> *散列表工作机制*__\n###**存储**\n&nbsp;&nbsp; <font size=3> 使用一个数组实现的无序符号表\n&nbsp;&nbsp; <font size=3> 意味着, 数组创建后, 难于扩展（某些哈希表被基本填满时, 性能下降得非常严重）\n&nbsp;&nbsp; <font size=3> 要么预设足够的空间, 要么定期将数据迁移到更大的哈希表\n\n###**查找**\n&nbsp;&nbsp; <font size=3> 首先, 用散列函数将被查找的键转化为数组的一个索引\n&nbsp;&nbsp; <font size=3> 其次, 处理碰撞冲突\n- 拉链法\n&nbsp;&nbsp; <font size=3> 1. 使用原始的链表数据类型来扩展 SequentialSerchT\n&nbsp;&nbsp; <font size=3> 2. 为 M 个元素分别构建符号表来保存散列到这里的键\n- 线性探测法\n&nbsp;&nbsp; <font size=3> 用大小为 M 的数组保存 N 个键值对（M > N, 依靠数组中空位解决碰撞冲突, 此策略的所有方法统称为开放地址散列表） \n\n##__ <font color='blue'> *散列表在 Java 中的相关实现 : HashMap*__\n###**java.lang.Object 的规范**\n1. 如果一个对象的 equals 方法做比较所用到的信息没有被修改的话, 那么, 对该对象调用 hashCode 方法多次, 必须始终如一地返回同一个整数\n2. 如果两个对象根据 equals (Object) 方法是相等, 那么调用这两个对象中任意一个对象的 hashCode 方法必须产生同样的整数结果\n3. 对于不相等的对象产生截然不同的整数结果, 有可能提高散列表 (hash table) 的性能\n\n###**HashMap 失效的情况**\n```java\npackage com.yuzhouwan.hashCode2;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic final class PhoneNumber {\n\tprivate final short areaCode;\n\tprivate final short exchange;\n\tprivate final short extension;\n\n\tpublic PhoneNumber(int areaCode, int exchange, int extension) {\n\t\trangeCheck(areaCode, 999, \"area code\");\n\t\trangeCheck(exchange, 999, \"exchange\");\n\t\trangeCheck(extension, 9999, \"extension\");\n\t\tthis.areaCode = (short) areaCode;\n\t\tthis.exchange = (short) exchange;\n\t\tthis.extension = (short) extension;\n\t}\n\n\tprivate static void rangeCheck(int arg, int max, String name) {\n\t\tif (arg < 0 || arg > max)\n\t\t\tthrow new IllegalArgumentException(name + \": \" + arg);\n\t}\n\n\t@Override\n\tpublic int hashCode() {\n\t\tfinal int prime = 31;\n\t\tint result = 1;\n\t\tresult = prime * result + areaCode;\n\t\tresult = prime * result + exchange;\n\t\tresult = prime * result + extension;\n\t\treturn result;\n\t}\n\n\t/**\n\t * If u put the param that is not Object and forget use the annotation that name is 'Override', \n\t * the equals method loses efficacy and u will find the reason hardly.\n\t */\n\t@Override\n\tpublic boolean equals(Object o) {\n\t\tif(o == this)\n\t\t\treturn true;\n\t\tif(!(o instanceof PhoneNumber))\n\t\t\treturn false;\n\t\tPhoneNumber pn = (PhoneNumber)o;\n\t\treturn pn.extension == extension && \n\t\t\tpn.exchange == exchange && \n\t\t\tpn.areaCode == areaCode;\n\t}\n\t\n\tpublic boolean equals2(Object obj) {\n\t\tif (this == obj)\n\t\t\treturn true;\n\t\tif (obj == null)\n\t\t\treturn false;\n\t\tif (getClass() != obj.getClass())\n\t\t\treturn false;\n\t\tPhoneNumber other = (PhoneNumber) obj;\n\t\tif (areaCode != other.areaCode)\n\t\t\treturn false;\n\t\tif (exchange != other.exchange)\n\t\t\treturn false;\n\t\tif (extension != other.extension)\n\t\t\treturn false;\n\t\treturn true;\n\t}\n\n\t/**\n\t * if u do not rewrite the hashCode method, \n\t * u will get the different hashCode when u init the same object, then the hashMap will work unusually.\n\t */\n\tpublic static void main(String... args) {\n\t\tMap<PhoneNumber, String> m = new HashMap<PhoneNumber, String>();\n\n\t\tPhoneNumber pn = new PhoneNumber(408, 867, 5309);\n\t\tm.put(pn, \"Jenny\");\n\n\t\tSystem.out.println(\"pn\\' hashCode: \" + pn.hashCode() + \" - \"\n\t\t\t\t+ m.get(pn));\n\n\t\tpn = new PhoneNumber(408, 867, 5309);\n\t\tSystem.out.println(\"pn\\' hashCode: \" + pn.hashCode() + \" - \"\n\t\t\t\t+ m.get(pn));\n\t}\n}\n```\n&nbsp;&nbsp; <font size=3> 如果没有 hashCode 的结果：\n```java\npn' hashCode: 909751202 - Jenny\npn' hashCode: 104885374 - null\n```\n\n###**处方**\n1. 把某个非零长数值, 比如说 17, 保存在一个叫 result 的 int 类型变量中\n2. 对于对象中每一个关键域 f（指 equals 方法中考虑的每个域）, 完成以下步骤：\n\ta.为该域计算 int 类型的散列码 c：\n\t\ti.\t如果该域是 boolean 类型, 则计算 (f?0:1) \n\t\tii.\t如果该域是 byte、char、short 或者 int 类型, 则计算  (int) f\n\t\tiii.\t如果该域是 long 类型, 则计算  (int)  (f ^  (f >>> 32) ) \n\t\tiv.\t如果该域是 float 类型, 则计算 Float.floatToIntBits (f) \n\t\tv.\t如果该域是 double 类型, 则计算 Double.doubleToLongBits (f) 得到一个 long 类型的值, 然后按照步骤 2.a.iii, 对该 long 型值计算散列值\n\t\tvi.\t如果该域是一个对象引用, 并且该类的 equals 方法通过递归调用 equals 的方式来比较这个域, 则同样对这个域递归调用 hashCode。\n\t\t\t如果要求一个更为复杂的比较, 则为这个域计算一个 \"规范表示 (canonical representation)\", 然后针对这个范式表示调用 hashCode。\n\t\t\t如果这个域的值为 null, 则返回 0 (这货其他某个常数, 但习惯上使用 0) \n\t\tvii.\t如果该域是一个数组, 则把每一个元素当做单独的域来处理。\n\t\t\t也就是说, 递归地应用上述规则, 对每个重要的元素计算一个散列码, 然后根据步骤 2.b 中的做法把这些散列值组合起来\n\tb.按照下面的公式, 把步骤 a 中计算得到的散列码 c 组合到 result 中：\n\t\tresult = 37 * result + c;\n3. 返回 result\n4. 写完了 hashCode 方法之后, 问自己 \"是否相等的实例具有相等的散列码\" 。如果不是的话, 找出原因, 并修改错误。\n\n###**冗余域 (redundant field)**\n&nbsp;&nbsp; <font size=3> 如果一个域的值可以根据参与计算的其他域值计算出来, 则把这样的域排除在外是可以接受的。\n\n##__ <font color='blue'> *ConcurrentHashMap 如何实现线程安全*__\n###ConcurrentHashMap 中加了 lock 的方法 &nbsp; <font size=3> **_(scanAndLockForPut、scanAndLock、lock 用来添加锁, 并使用 try-finally 释放锁, 以及使用 sun.misc.Unsafe 提供 volatile 变量)_**\n```java\n\t+ java.util.concurrent.ConcurrentHashMap.Segment<K, V>\n\n\t\t- scanAndLockForPut\t+\tunclock\n\t\t\tput\n\t\t- scanAndLock\t\t+\tunclock\n\t\t\tremove、replace\n\t\t- lock\t\t\t+\tunclock\n\t\t\tclear\n\t\t- java.util.concurrent.locks.ReentrantLock.lock()\t+ unlock()\n\t\t\tsize、containsValue\n\n\n\t+ java.util.concurrent.locks.ReentrantLock.lock() -> java.util.concurrent.locks.ReentrantLock.Sync.lock()\n\t+ java.util.concurrent.locks.ReentrantLock.unlock() -> java.util.concurrent.locks.AbstractQueuedSynchronizer.release(int)\n\n\t\twriteObject(Serialization Support)\n```\t\t\n\t\n###sun.misc.Unsafe.getObjectVolatile(Object, long)\n```java\nget\t\t\t// manually integrate access methods to reduce overhead\ncontainsKey\t\t// same as get() except no need for volatile value read\n```\n\n\n###readObject 中读取流中所有的 Object__*（小技巧）*__\n```java\n    // Read the keys and values, and put the mappings in the table\n    for (;;) {\t\t\t\t\t\t// = while(true)\n        K key = (K) s.readObject();\t\t\t\t//java.io.ObjectInputStream\n        V value = (V) s.readObject();\n        if (key == null)\n            break;\t\t\t\t\t\t//只有达到这个条件, 才可以退出这个死循环\n        put(key, value);\n    }\n```\n\n[1]:http://baike.baidu.com/link?url=kMtqNs5r1u9kIx4w6yBze9lTiitzfFsk2jUNvjW4lJ7zXNYTUSp0rXq8kwW9t0l-mv2eEzA47GYUyUGfoSS3x\n","slug":"散列表","updated":1416130772000,"excerpt":"","_id":"8d8a2twu1xotrk7c","comments":true,"layout":"post","photos":[],"link":""},{"title":"海纳百川","date":2147454848000,"tags":["baw29kp8rfitqhbs"],"categories":["otry90hevjbvt7xb"],"content":"<h1 id=\"google\"><strong><em>google</em></strong></h1>\n<p><img src=\"/../logos/google.png\" alt=\"\"><br><a href=\"https://g.wen.lu/\" target=\"_blank\" rel=\"external\">https://g.wen.lu/</a> &nbsp;&nbsp;&nbsp;&nbsp;<font color=\"green\"><em>(do not click, please copy)</em></font></p>\n<p><br></p>\n<h1 id=\"anything\"><strong><em>anything</em></strong></h1>\n<p><img src=\"/../logos/hejizhan.png\" alt=\"\"><br><a href=\"http://www.hejizhan.com/\" target=\"_blank\" rel=\"external\">http://www.hejizhan.com/</a></p>\n<p><br></p>\n<h1 id=\"book\"><strong><em>book</em></strong></h1>\n<p><img src=\"/../logos/safari.png\" alt=\"\"><br><a href=\"https://www.safaribooksonline.com/\" target=\"_blank\" rel=\"external\">https://www.safaribooksonline.com/</a></p>\n<p><img src=\"/../logos/it_ebooks.png\" alt=\"\"><br><a href=\"http://www.it-ebooks.info/\" target=\"_blank\" rel=\"external\">http://www.it-ebooks.info/</a></p>\n<p><img src=\"/../logos/salttiger.png\" alt=\"\"><br><a href=\"http://www.salttiger.com/\" target=\"_blank\" rel=\"external\">http://www.salttiger.com/</a></p>\n<p><img src=\"/../logos/packtpub.png\" alt=\"\"><br><a href=\"https://www.packtpub.com/packt/offers/free-learning\" target=\"_blank\" rel=\"external\">https://www.packtpub.com/packt/offers/free-learning</a></p>\n<p><br></p>\n<h1 id=\"video\"><strong><em>video</em></strong></h1>\n<p><img src=\"/../logos/it_cast.png\" alt=\"\"><br><a href=\"http://www.itcast.cn/channel/video.shtml\" target=\"_blank\" rel=\"external\">http://www.itcast.cn/channel/video.shtml</a></p>\n<p><br></p>\n<h3 id=\"JUDGMENT_DAY\"><font color=\"red\"><strong>JUDGMENT DAY</strong></font></h3>\n<p><img src=\"/../logos/Year_2038_problem.gif\" alt=\"Year_2038_problem\"><br><a href=\"https://en.wikipedia.org/wiki/Year_2038_problem\" target=\"_blank\" rel=\"external\">Animation showing how the date would reset, represented as a signed 32-bit integer (at 03:14:08 UTC on 19 January 2038).</a></p>\n","source":"_posts/海纳百川.md","raw":"title: 海纳百川\ndate: 2038-01-19 03:14:08\ntags:\n - Year_2038_problem\ncategories:\n - Year_2038_problem\n---\n\n# __*google*__\n\n![][411]\n[https://g.wen.lu/][412] &nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>*(do not click, please copy)*\n\n<br/>\n\n\n# __*anything*__\n\n![][311]\n[http://www.hejizhan.com/][312]\n\n<br/>\n\n\n\n# __*book*__\n\n![][211]\n[https://www.safaribooksonline.com/][212]\n\n![][221]\n[http://www.it-ebooks.info/][222]\n\n![][231]\n[http://www.salttiger.com/][232]\n\n![][241]\n[https://www.packtpub.com/packt/offers/free-learning][242]\n\n<br/>\n\n\n# __*video*__\n\n![][111]\n[http://www.itcast.cn/channel/video.shtml][112]\n\n<br/>\n\n\n\n###<font color='red'>__JUDGMENT DAY__\n![Year_2038_problem][1000]\n[Animation showing how the date would reset, represented as a signed 32-bit integer (at 03:14:08 UTC on 19 January 2038).][999]\n\n\n\n[111]:/../logos/it_cast.png\n\n[211]:/../logos/safari.png\n[221]:/../logos/it_ebooks.png\n[231]:/../logos/salttiger.png\n[241]:/../logos/packtpub.png\n\n[311]:/../logos/hejizhan.png\n\n[411]:/../logos/google.png\n\n\n\n[112]:http://www.itcast.cn/channel/video.shtml\n\n[212]:https://www.safaribooksonline.com/\n[222]:http://www.it-ebooks.info/\n[232]:http://www.salttiger.com/\n[242]:https://www.packtpub.com/packt/offers/free-learning\n\n[312]:http://www.hejizhan.com/\n\n[412]:https://g.wen.lu/\n\n\n[999]:https://en.wikipedia.org/wiki/Year_2038_problem\n[1000]:/../logos/Year_2038_problem.gif\n","slug":"海纳百川","updated":1439456615000,"excerpt":"","_id":"3cdgmchgzaj82c9h","comments":true,"layout":"post","photos":[],"link":""},{"title":"Antlr","date":1422846566000,"tags":["1de012ov3n4zps8v"],"categories":["c4sd4umtpej6g9hp"],"content":"<h2 id=\"什么是_Antlr?\"><strong><font color=\"blue\"><em>什么是 Antlr?</em></font></strong></h2>\n<p>&nbsp;&nbsp; <font size=\"3\">ANTLR—Another Tool for Language Recognition, 其前身是 PCCTS, 它为包括 Java, C++, C# 在内的语言提供了一个通过语法描述来自动构造自定义语言的识别器 (recognizer) , 编译器 (parser) 和解释器 (translator) 的框架。 - - <a href=\"http://baike.baidu.com/link?url=0M76AbufdfB3BPoqptG8FqFZ_U-U6IloEsnc_9sCA9iPNhmFXjLCvf5MULP9YXIITmnafLH4r8GMuZ4_R_D3hq\" target=\"_blank\" rel=\"external\">百度百科</a></font></p>\n<p>&nbsp; <font size=\"3\"><em>ANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files. It’s widely used to build languages, tools, and frameworks. From a grammar, ANTLR generates a parser that can build and walk parse trees.</em> - - <a href=\"http://www.antlr.org/\" target=\"_blank\" rel=\"external\">Antlr Official Site</a></font></p>\n<p>&nbsp; <font size=\"3\"><em>In computer-based language recognition, ANTLR (pronounced Antler), or ANother Tool for Language Recognition, is a parser generator that uses LL(*) parsing.</em> - - <a href=\"http://en.wikipedia.org/wiki/ANTLR\" target=\"_blank\" rel=\"external\">WIKIPEDIA</a></font></p>\n<h2 id=\"为什么要有_Antlr?\"><strong><font color=\"blue\"><em>为什么要有 Antlr?</em></font></strong></h2>\n<h3 id=\"简易性\">简易性</h3>\n<pre><code>-<span class=\"ruby\"> 可以通过断言 (<span class=\"constant\">Predicate</span>) 解决识别冲突\n</span>-<span class=\"ruby\"> 支持动作 (<span class=\"constant\">Action</span>) 和返回值 (<span class=\"constant\">Return</span> <span class=\"constant\">Value</span>)\n</span>-<span class=\"ruby\"> 它可以根据输入自动生成语法树并可视化的显示出来</span>\n</code></pre><h3 id=\"模块化\">模块化</h3>\n<pre><code>-<span class=\"ruby\"> 复杂情况下，需要基于语法树遍历 (walking the tree) 生成目标代码\n</span>-<span class=\"ruby\"> <span class=\"constant\">Embeded</span> action将处理代码跟语法描述混合起来，语法复杂时使语法文件臃肿\n</span>-<span class=\"ruby\"> 语法可能经常需要修改\n</span>-<span class=\"ruby\"> 语法的主要表达式却不会变动，将语法识别与转换、生成 (目标代码) 等处理分离</span>\n</code></pre><h2 id=\"Antlr_工作机制\"><strong><font color=\"blue\"><em>Antlr 工作机制</em></font></strong></h2>\n<h3 id=\"词法分析器_(Lexer)\">词法分析器 (Lexer)</h3>\n<pre><code>分析量化字符流，翻译成离散的字符组 (也就是一堆 Token), 包括关键字，标识符，符号 (symbols) 和操作符，以供语法分析器使用\n</code></pre><h3 id=\"语法分析器_(Parser)\">语法分析器 (Parser)</h3>\n<pre><code>将 Tokens 组织起来，并转换成为目标语言语法 (默认是 java) 定义所允许的序列\n</code></pre><h3 id=\"树分析器_(Tree_Parser)\">树分析器 (Tree Parser)</h3>\n<pre><code>用于对语法分析生成的抽象语法树进行遍历，并在先序经过每个树节点的时候，进行一些定制操作\n</code></pre><h2 id=\"Antlr_运作流程\"><strong><font color=\"blue\"><em>Antlr 运作流程</em></font></strong></h2>\n<h3 id=\"编写_-g/-g4_文件_(asdf-g4)\">编写 .g/.g4 文件 (asdf.g4)</h3>\n<figure class=\"highlight antlr\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">grammar asdf;</div><div class=\"line\">say</div><div class=\"line\">\t: 'asdf say: ' Name</div><div class=\"line\">\t;</div><div class=\"line\">Name</div><div class=\"line\">\t: [a-z]+</div><div class=\"line\">\t;</div><div class=\"line\">WS</div><div class=\"line\">\t:[ \\t\\r\\n]+ -&gt; skip</div><div class=\"line\">\t;</div></pre></td></tr></table></figure>\n\n<h3 id=\"使用_antlr_词法/语法_分析\">使用 antlr 词法/语法 分析</h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">java org.antlr.v4.Tool asdf.g4</div><div class=\"line\">-------&gt;</div><div class=\"line\">asdf.tokens</div><div class=\"line\">asdfLexer.tokens</div><div class=\"line\">asdfLexer.java</div><div class=\"line\">asdfListener.java</div><div class=\"line\">asdfBaseListener.java</div><div class=\"line\">asdfParser.java</div></pre></td></tr></table></figure>\n\n<h3 id=\"编译，可视化\">编译，可视化</h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">javac asdf*.java</div><div class=\"line\">java org.antlr.v4.runtime.misc.TestRig asdf say -gui -tree</div><div class=\"line\"></div><div class=\"line\">input a sentence ending with ^Z:</div><div class=\"line\">\tsay hello</div></pre></td></tr></table></figure>\n\n<p><img src=\"/../2015-2-2/say-hello.png\" alt=\"say-hello\"></p>\n<h2 id=\"那些年一起踩过的坑_!\"><strong><font color=\"blue\"><em>那些年一起踩过的坑 !</em></font></strong></h2>\n<h3 id=\"给每次_antlr_的结果文件添加_package\">给每次 antlr 的结果文件添加 package</h3>\n<pre><code>在 .g4 中使用 @header{ <span class=\"keyword\">...</span> } 添加 \n</code></pre><figure class=\"highlight antlr\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"at_rule\">@<span class=\"keyword\">header{</span></span></div><div class=\"line\">\tpackage com.yuzhouwan.antlr;</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<h3 id=\"使用_if-else_在_exit/enter()_中判别，节点与子节点之间的关系，确定是否是_operator\">使用 if-else 在 exit/enter() 中判别，节点与子节点之间的关系，确定是否是 operator</h3>\n<figure class=\"highlight antlr\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">say</div><div class=\"line\">\t: <span class=\"string\">'say'</span> <span class=\"keyword\">Colon</span> Name\t#<span class=\"keyword\">Colon</span></div><div class=\"line\">\t;</div></pre></td></tr></table></figure>\n\n\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">asdfListener 将会得到一个定位粒度为 Colon 的访问节点</div><div class=\"line\"></div><div class=\"line\"><span class=\"javadoc\">/**</span></div><div class=\"line\"> * Enter a parse tree produced by the {@code Colon}</div><div class=\"line\"> * labeled alternative in {@link asdfParser#say}.</div><div class=\"line\"> *<span class=\"javadoctag\"> @param</span> ctx the parse tree</div><div class=\"line\"> */</div><div class=\"line\"><span class=\"keyword\">void</span> enterColon(asdfParser.ColonContext ctx);</div><div class=\"line\"><span class=\"javadoc\">/**</span></div><div class=\"line\"> * Exit a parse tree produced by the {@code Colon}</div><div class=\"line\"> * labeled alternative in {@link asdfParser#say}.</div><div class=\"line\"> *<span class=\"javadoctag\"> @param</span> ctx the parse tree</div><div class=\"line\"> */</div><div class=\"line\"><span class=\"keyword\">void</span> exitColon(asdfParser.ColonContext ctx);</div></pre></td></tr></table></figure>\n\n","source":"_posts/Antlr4.md","raw":"title: Antlr\ndate: 2015-02-02 11:09:26\ntags:\n- Antlr\ncategories:\n- Antlr\n\n---\n\n## __<font color='blue'>*什么是 Antlr?*__\n\n&nbsp;&nbsp; <font size=3>ANTLR—Another Tool for Language Recognition, 其前身是 PCCTS, 它为包括 Java, C++, C# 在内的语言提供了一个通过语法描述来自动构造自定义语言的识别器 (recognizer) , 编译器 (parser) 和解释器 (translator) 的框架。 - - [百度百科][1]\n\n&nbsp; <font size=3>_ANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files. It's widely used to build languages, tools, and frameworks. From a grammar, ANTLR generates a parser that can build and walk parse trees._ - - [Antlr Official Site][2]\n\n&nbsp; <font size=3>_In computer-based language recognition, ANTLR (pronounced Antler), or ANother Tool for Language Recognition, is a parser generator that uses LL(*) parsing._ - - [WIKIPEDIA][3]\n\n## __<font color='blue'>*为什么要有 Antlr?*__\n### 简易性\n\n\t- 可以通过断言 (Predicate) 解决识别冲突\n\t- 支持动作 (Action) 和返回值 (Return Value)\n\t- 它可以根据输入自动生成语法树并可视化的显示出来\n\n### 模块化\n\t- 复杂情况下，需要基于语法树遍历 (walking the tree) 生成目标代码\n\t- Embeded action将处理代码跟语法描述混合起来，语法复杂时使语法文件臃肿\n\t- 语法可能经常需要修改\n\t- 语法的主要表达式却不会变动，将语法识别与转换、生成 (目标代码) 等处理分离\n\n## __<font color='blue'>*Antlr 工作机制*__\n\n###词法分析器 (Lexer)\n\t分析量化字符流，翻译成离散的字符组 (也就是一堆 Token), 包括关键字，标识符，符号 (symbols) 和操作符，以供语法分析器使用\n\n###语法分析器 (Parser)\n\t将 Tokens 组织起来，并转换成为目标语言语法 (默认是 java) 定义所允许的序列\n\n###树分析器 (Tree Parser)\n\t用于对语法分析生成的抽象语法树进行遍历，并在先序经过每个树节点的时候，进行一些定制操作\n\n\n## __<font color='blue'>*Antlr 运作流程*__\n\n###编写 .g/.g4 文件 (asdf.g4)\n```antlr\ngrammar asdf;\nsay\n\t: 'asdf say: ' Name\n\t;\nName\n\t: [a-z]+\n\t;\nWS\n\t:[ \\t\\r\\n]+ -> skip\n\t;\n```\n\n###使用 antlr 词法/语法 分析\n```java\njava org.antlr.v4.Tool asdf.g4\n------->\nasdf.tokens\nasdfLexer.tokens\nasdfLexer.java\nasdfListener.java\nasdfBaseListener.java\nasdfParser.java\n```\n\n###编译，可视化\n```java\njavac asdf*.java\njava org.antlr.v4.runtime.misc.TestRig asdf say -gui -tree\n\ninput a sentence ending with ^Z:\n\tsay hello\n```\n![say-hello][4]\n\n##__<font color='blue'>*那些年一起踩过的坑 !*__\n\n###给每次 antlr 的结果文件添加 package\n\t在 .g4 中使用 @header{ ... } 添加 \n```antlr\n@header{\n\tpackage com.yuzhouwan.antlr;\n}\n```\n\n###使用 if-else 在 exit/enter() 中判别，节点与子节点之间的关系，确定是否是 operator\n```antlr\nsay\n\t: 'say' Colon Name\t#Colon\n\t;\n```\n\n```java\n\nasdfListener 将会得到一个定位粒度为 Colon 的访问节点\n\n/**\n * Enter a parse tree produced by the {@code Colon}\n * labeled alternative in {@link asdfParser#say}.\n * @param ctx the parse tree\n */\nvoid enterColon(asdfParser.ColonContext ctx);\n/**\n * Exit a parse tree produced by the {@code Colon}\n * labeled alternative in {@link asdfParser#say}.\n * @param ctx the parse tree\n */\nvoid exitColon(asdfParser.ColonContext ctx);\n```\n\n[1]:http://baike.baidu.com/link?url=0M76AbufdfB3BPoqptG8FqFZ_U-U6IloEsnc_9sCA9iPNhmFXjLCvf5MULP9YXIITmnafLH4r8GMuZ4_R_D3hq\n[2]:http://www.antlr.org/\n[3]:http://en.wikipedia.org/wiki/ANTLR\n[4]:/../2015-2-2/say-hello.png\n","slug":"Antlr4","updated":1420973871000,"excerpt":"","_id":"rmw8s9n3g5m99v69","comments":true,"layout":"post","photos":[],"link":""},{"title":"DIRT","date":1414995302000,"tags":["bqus80m5xcxzaorh"],"categories":["ifi2x4menzkubm48"],"content":"<h3 id=\"DIRT:数据密集型实时(data-intensive_real-time)\">DIRT:数据密集型实时(data-intensive real-time)</h3>\n<p><strong>为什么适用于 Node 开发 ? </strong></p>\n<p><font size=\"4\">&nbsp;&nbsp;因为 Node 自身在 I/O 上非常轻量，它善于将数据从一个管道混排 或 代理到另一个管道上，这能在处理大量请求时持有很多开放的连接，并且只占用一小部分内存。(如同浏览器一样，保证了响应能力)</font></p>\n<p><strong>Web 发展形势</strong></p>\n<p><font size=\"4\">&nbsp;&nbsp;不管是用实时组件增强已有程序，还是打造全新的程序，Web 都在朝着响应性和协作型环境逐渐进发。</font></p>\n<p><font size=\"4\">&nbsp;&nbsp;而这种新型的 Web 应用程序需要一个能够实时相应大量并发请求的平台来支撑它们。(除此之外，还有 I/O 负载较重的程序也可以用到)</font></p>\n<p><strong>Node 作为 JavaScript 程序的平台</strong></p>\n<ul>\n<li>Timer API (for example, setTimeout)</li>\n<li>Console API (for example, console.log)</li>\n<li>Network and File I/O modules (HTTP, TLS, HTTPS, filesystem (POSIX), Datagram (UDP), and NET (TCP))</li>\n</ul>\n","source":"_posts/DIRT.md","raw":"title: DIRT\ndate: 2014-11-03 14:15:02\ntags: \n- Node.js\ncategories: \n- Node.js\n---\n###DIRT:数据密集型实时(data-intensive real-time)\n__为什么适用于 Node 开发 ? __\n\n<font size=4>&nbsp;&nbsp;因为 Node 自身在 I/O 上非常轻量，它善于将数据从一个管道混排 或 代理到另一个管道上，这能在处理大量请求时持有很多开放的连接，并且只占用一小部分内存。(如同浏览器一样，保证了响应能力)\n\n__Web 发展形势__\n<font size=4>&nbsp;&nbsp;不管是用实时组件增强已有程序，还是打造全新的程序，Web 都在朝着响应性和协作型环境逐渐进发。\n<font size=4>&nbsp;&nbsp;而这种新型的 Web 应用程序需要一个能够实时相应大量并发请求的平台来支撑它们。(除此之外，还有 I/O 负载较重的程序也可以用到)\n\n__Node 作为 JavaScript 程序的平台__\n- Timer API (for example, setTimeout)\n- Console API (for example, console.log)\n- Network and File I/O modules (HTTP, TLS, HTTPS, filesystem (POSIX), Datagram (UDP), and NET (TCP))","slug":"DIRT","updated":1415065386000,"excerpt":"","_id":"2jri9d9jo6z7stv1","comments":true,"layout":"post","photos":[],"link":""},{"title":"Real-time ML with Spark","date":1439466621000,"tags":["oi61cro9f77gtvjd","bv1x3obr9dfbv4h4"],"categories":["w8x7zc0mnzcw36k5"],"content":"<h2 id=\"什么是_Spark?\"><strong><font color=\"blue\"><em>什么是 Spark?</em></font></strong></h2>\n<p>&nbsp;&nbsp; <font size=\"3\"> Apache Spark™ is a fast and general engine for large-scale data processing. - - <a href=\"http://spark.apache.org/\" target=\"_blank\" rel=\"external\">Official website</a></font></p>\n<p><br></p>\n<h2 id=\"为什么要有_Spark?\"><strong><font color=\"blue\"><em>为什么要有 Spark?</em></font></strong></h2>\n<h3 id=\"分布式\">分布式</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">具备经济、快速、可靠、易扩充、数据共享、设备共享、通讯方便、灵活等分布式所具备的特性</div></pre></td></tr></table></figure>\n\n<h3 id=\"高层次抽象\">高层次抽象</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">RDD (Resilient Distributed Datasets) 提供 一个可以被并行计算的 不变、分区的数据集 抽象</div></pre></td></tr></table></figure>\n\n<h3 id=\"快速计算能力\">快速计算能力</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">内存计算 基于内存的迭代计算框架，能够避免计算结果落地，磁盘 I/O 所带来的瓶颈</div><div class=\"line\">Machine Learning、Data mining 等多需要递归地计算，因此非常适合实现这些算法</div></pre></td></tr></table></figure>\n\n<h3 id=\"高效性能\">高效性能</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">DAG (Directed Acyclic Grap) 利用有向无环图，构建优化任务中 父 RDD 和 子 RDD 的依赖关系  (Like Ooize)</div><div class=\"line\">依赖分为两种，一个为窄依赖，如 map/filter/union 等；另一种为宽依赖，如 groupByKey 等</div><div class=\"line\">在划分依赖时，join 需要额外考虑 <span class=\"string\">\"co-partitioner\"</span>：</div><div class=\"line\">    <span class=\"number\">1.</span> 如果 RDD 和 cogroup 有相同的 数据结构，将会确定一个 OneToOneDependency</div><div class=\"line\">    <span class=\"number\">2.</span> 反之，则说明 join 的时候，需要 shuffle (ShuffleDependency)</div><div class=\"line\">[建议]:<span class=\"string\">\"wide dependencies 只有等到所有 父 partiton 计算完，并传递结束，才能继续进行下一步运算，所以应尽量减少宽依赖，避免失败后 recompute 的成本\"</span></div></pre></td></tr></table></figure>\n\n<h3 id=\"容错性\">容错性</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">lineage 血统，能在计算失败的时候，将会找寻 最小重新计算损耗的 结点，而不是全部重复计算</div></pre></td></tr></table></figure>\n\n<p><br></p>\n<h2 id=\"Spark_核心组件\"><strong><font color=\"blue\"><em>Spark 核心组件</em></font></strong></h2>\n<h3 id=\"Spark_SQL\">Spark SQL</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">同时支持 HiveQL/UDFs/SerDes 等多样性的数据源，并采用 JDBC/ODBC 等标准化连接驱动，保证其通用性</div></pre></td></tr></table></figure>\n\n<h3 id=\"Spark_GrapX\">Spark GrapX</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">支持在 graph 或 collection 中查看数据，并提供丰富的 图形处理 API</div></pre></td></tr></table></figure>\n\n<h3 id=\"Spark_Streaming\">Spark Streaming</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">将数据流 按 时间间隔 Duration 划分为一组连续的 RDD，这些 RDD 抽象为 DStream</div><div class=\"line\">随后，通过对 DStream 这个 high-level 抽象的操作，实现对底层 标记了 时间间隙 的 RDD 组的操控</div></pre></td></tr></table></figure>\n\n<h3 id=\"Spark_MLbase\">Spark MLbase</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">提供了对 Machine Learning 的易用、高效的实现</div><div class=\"line\">总体的结构，基于 Spark，自底向上分别是，MLlib/MLI/ML Optimizer。</div><div class=\"line\">    <span class=\"number\">1.</span> MLlib 这一层，设计了 本地/分布式 的矩阵，对稀疏数据的支持，多模型的训练，提供了 计算模型 和 逻辑的 API</div><div class=\"line\">    <span class=\"number\">2.</span> MLI 主要任务则是 提供 表针采集器 和 逻辑规则，并进一步对 高层次 ML 编程抽象成接口</div><div class=\"line\">    <span class=\"number\">3.</span> ML Optimizer 则是通过自动构建 ML 的 pipe 管道路径实现 ML 优化器的作用。</div><div class=\"line\">       同时，此优化器还解决了一个在 MLI 和 MLlib 中 表征采集器 和 ML 逻辑规则的搜索问题</div></pre></td></tr></table></figure>\n\n<p><br></p>\n<h2 id=\"Spark_实时机器学习\"><strong><font color=\"blue\"><em>Spark 实时机器学习</em></font></strong></h2>\n<h3 id=\"什么是机器学习？\">什么是<a href=\"https://en.wikipedia.org/wiki/Machine_learning\" target=\"_blank\" rel=\"external\">机器学习</a>？</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Wikipedia 给出的定义是，一个计算机科学的子领域，由 模式识别 和 人工智能中的计算机学习理论 演变而来</div><div class=\"line\">探索 结构化的、可学习的规则引擎，如何用来对数据 进行训练 和 预测</div></pre></td></tr></table></figure>\n\n<h3 id=\"什么又是_Real-time_机器学习呢？\">什么又是 Real-time 机器学习呢？</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">一般性的 机器学习 的对象 是一堆 offline 的训练集，通过对这些数据的学习，来确立模型</div><div class=\"line\">如果数据是快速变化的，这时就需要将 新数据 分配好权重，加入到目标训练集中；之后，将预测出来的结果，再次反馈到 数据模型中去</div></pre></td></tr></table></figure>\n\n<h3 id=\"Real-time_和_No_Real-time_的本质区别在哪儿？\">Real-time 和 No Real-time 的本质区别在哪儿？</h3>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">因为 实时模型 是动态更新的，实现算法上，比 非实时的 ML 需要考虑，如何避免依赖 将 新数据 和 旧数据 整合在一块再计算所带来的性能问题</div><div class=\"line\">更多时候，长期积累的数据，是很难再做到全量计算 (Like 多项式贝叶斯 Multinomial naive bayes, 用于处理 dataset 过大，而内存不足的情况)</div></pre></td></tr></table></figure>\n\n<p><br></p>\n<h2 id=\"利用_Spark_实现_Real-time_ML\"><strong><font color=\"blue\"><em>利用 Spark 实现 Real-time ML</em></font></strong></h2>\n<h3 id=\"源数据流\">源数据流</h3>\n<p>&nbsp;&nbsp; <font size=\"2\"> I.    利用 java.util.Random 产生满足高斯分布的随机数据，再通过 <a href=\"http://www.scalanlp.org/\" target=\"_blank\" rel=\"external\">breeze</a> 放入到 vector 中，作为 特征值<br>&nbsp;&nbsp; <font size=\"2\"> II.    在 generateNoisyData 中，将这个 vector 做 inner product, 并加入一点噪声数据，作为 label</font></font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">val</span> MaxEvents = <span class=\"number\">100</span></div><div class=\"line\"><span class=\"keyword\">val</span> NumFeatures = <span class=\"number\">100</span></div><div class=\"line\"><span class=\"keyword\">val</span> random = <span class=\"keyword\">new</span> Random()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">def</span> generateRandomArray(n: Int) = Array.tabulate(n)(_ =&gt; random.nextGaussian())</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">val</span> w = <span class=\"keyword\">new</span> DenseVector(generateRandomArray(NumFeatures))</div><div class=\"line\"><span class=\"keyword\">val</span> intercept = random.nextGaussian() * <span class=\"number\">10</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">def</span> generateNoisyData(n: Int) = {</div><div class=\"line\">  (<span class=\"number\">1</span> to n).map { i =&gt;</div><div class=\"line\">    <span class=\"keyword\">val</span> x = <span class=\"keyword\">new</span> DenseVector(generateRandomArray(NumFeatures))</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// inner product</span></div><div class=\"line\">    <span class=\"keyword\">val</span> y: Double = w.dot(x)</div><div class=\"line\">    <span class=\"keyword\">val</span> noisy = y + intercept</div><div class=\"line\">    (noisy, x)</div><div class=\"line\">  }</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> III.    通过 socket 将数据 发送到指定端口</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> (args.length != <span class=\"number\">2</span>) {</div><div class=\"line\">  System.err.println(<span class=\"string\">\"Usage: &lt;port&gt; &lt;millisecond&gt;\"</span>)</div><div class=\"line\">  System.exit(<span class=\"number\">1</span>)</div><div class=\"line\">}</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">val</span> listener = <span class=\"keyword\">new</span> ServerSocket(args(<span class=\"number\">0</span>).toInt)</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) {</div><div class=\"line\">  <span class=\"keyword\">val</span> socket = listener.accept()</div><div class=\"line\"></div><div class=\"line\">  <span class=\"keyword\">new</span> Thread() {</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">override</span> <span class=\"keyword\">def</span> run = {</div><div class=\"line\"></div><div class=\"line\">      println(<span class=\"string\">\"Got client connected from: \"</span> + socket.getInetAddress)</div><div class=\"line\"></div><div class=\"line\">      <span class=\"keyword\">val</span> out = <span class=\"keyword\">new</span> PrintWriter(socket.getOutputStream(), <span class=\"keyword\">true</span>)</div><div class=\"line\">      <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) {</div><div class=\"line\">        Thread.sleep(args(<span class=\"number\">1</span>).toLong)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">val</span> num = random.nextInt(MaxEvents)</div><div class=\"line\">        <span class=\"keyword\">val</span> data = generateNoisyData(num)</div><div class=\"line\"></div><div class=\"line\">        data.foreach { <span class=\"keyword\">case</span> (y, x) =&gt;</div><div class=\"line\">          <span class=\"keyword\">val</span> xStr = x.data.mkString(<span class=\"string\">\",\"</span>)</div><div class=\"line\">          <span class=\"keyword\">val</span> content = s<span class=\"string\">\"$y\\t$xStr\"</span></div><div class=\"line\"></div><div class=\"line\">          println(content)</div><div class=\"line\"></div><div class=\"line\">          out.write(content)</div><div class=\"line\">          out.write(<span class=\"string\">\"\\n\"</span>)</div><div class=\"line\">        }</div><div class=\"line\">      }</div><div class=\"line\">      socket.close()</div><div class=\"line\">    }</div><div class=\"line\">  }.start()</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<p><br></p>\n<h3 id=\"实时_Machine_Learning_模型\">实时 Machine Learning 模型</h3>\n<p>&nbsp;&nbsp; <font size=\"2\"> I.    指定 spark-master/interval 等参数，创建 StreamingContext（此处可以利用 <font color=\"blue\">local[n]</font> 快速开发）</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> (args.length &lt; <span class=\"number\">4</span>) {</div><div class=\"line\">  System.err.println(<span class=\"string\">\"Usage: WindowCounter &lt;master&gt; &lt;hostname&gt; &lt;port&gt; &lt;interval&gt; \\n\"</span> +</div><div class=\"line\">    <span class=\"string\">\"In local mode, &lt;master&gt; should be 'local[n]' with n &gt; 1\"</span>)</div><div class=\"line\">  System.exit(<span class=\"number\">1</span>)</div><div class=\"line\">}</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">val</span> ssc = <span class=\"keyword\">new</span> StreamingContext(args(<span class=\"number\">0</span>), <span class=\"string\">\"ML Analysis\"</span>, Seconds(args(<span class=\"number\">3</span>).toInt))</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> II.    获取到发送过来的 源数据</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">val</span> stream = ssc.socketTextStream(args(<span class=\"number\">1</span>), args(<span class=\"number\">2</span>).toInt, StorageLevel.MEMORY_ONLY_SER)</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> III.    利用 DenseVector.zeros[Double] 创建全零的初始矩阵<br>&nbsp;&nbsp; <font size=\"2\"> IV.    使用 StreamingLinearRegressionWithSGD 创建 流式随机递归下降的线性回归 模型<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font size=\"2\">    目前 MLlib 只支持 Streaming ( KMeans / LinearRegression / LinearRegressionWithSGD ) in <a href=\"https://github.com/apache/spark/\" target=\"_blank\" rel=\"external\">Spark 1.4.1</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font size=\"2\">    Streaming MLlib 和普通的 MLlib 没有本质上的区别，只是输入的训练集是 DStream，需要使用 foreachRDD/map 进行 训练/预测 </font></font></font></font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">val</span> NumFeatures = <span class=\"number\">100</span></div><div class=\"line\"><span class=\"keyword\">val</span> zeroVector = DenseVector.zeros[Double](NumFeatures)</div><div class=\"line\"><span class=\"keyword\">val</span> model = <span class=\"keyword\">new</span> StreamingLinearRegressionWithSGD()</div><div class=\"line\">  .setInitialWeights(Vectors.dense(zeroVector.data))</div><div class=\"line\">  .setNumIterations(<span class=\"number\">1</span>)</div><div class=\"line\">  .setStepSize(<span class=\"number\">0.01</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">val</span> labeledStream = stream.map { event =&gt;</div><div class=\"line\">  <span class=\"keyword\">val</span> split = event.split(<span class=\"string\">\"\\t\"</span>)</div><div class=\"line\">  <span class=\"keyword\">val</span> y = split(<span class=\"number\">0</span>).toDouble</div><div class=\"line\">  <span class=\"keyword\">val</span> features = split(<span class=\"number\">1</span>).split(<span class=\"string\">\",\"</span>).map(_.toDouble)</div><div class=\"line\">  LabeledPoint(label = y, features = Vectors.dense(features))</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> V.    利用 模型 进行 train / predict</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">model.trainOn(labeledStream)</div><div class=\"line\"></div><div class=\"line\">   <span class=\"keyword\">val</span> predictAndTrue = labeledStream.transform { rdd =&gt;</div><div class=\"line\">     <span class=\"keyword\">val</span> latest = model.latestModel()</div><div class=\"line\">     rdd.map { point =&gt;</div><div class=\"line\">       <span class=\"keyword\">val</span> predict = latest.predict(point.features)</div><div class=\"line\">       (predict - point.label)</div><div class=\"line\">     }</div><div class=\"line\">   }</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> VI.    通过 MSE（Mean Squared Error） 均方差 和 RMSE（Root Mean Squared Error） 均方根误差 对模型的性能进行评估  (这里也可以使用 RegressionMetrics 来实现)</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">predictAndTrue.foreachRDD { (rdd, time) =&gt;</div><div class=\"line\">  <span class=\"keyword\">val</span> mse = rdd.map { <span class=\"keyword\">case</span> (err) =&gt; err * err }.mean()</div><div class=\"line\">  <span class=\"keyword\">val</span> rmse = math.sqrt(mse)</div><div class=\"line\">  println( s<span class=\"string\">\"\"\"</span></div><div class=\"line\">              |-------------------------------------------</div><div class=\"line\">              |Time: $time</div><div class=\"line\">      |-------------------------------------------</div><div class=\"line\">                  \"\"\".stripMargin)</div><div class=\"line\">  println(s<span class=\"string\">\"MSE current batch: Model : $mse\"</span>)</div><div class=\"line\">  println(s<span class=\"string\">\"RMSE current batch: Model : $rmse\"</span>)</div><div class=\"line\">  println(<span class=\"string\">\"...\\n\"</span>)</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> VII.    启动 Spark 上下文</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssc.start()</div><div class=\"line\">ssc.awaitTermination()</div></pre></td></tr></table></figure>\n\n<p><br></p>\n<h2 id=\"一劳永逸了？Not_at_all\"><strong><font color=\"blue\"><em>一劳永逸了？Not at all</em></font></strong></h2>\n<p>&nbsp;&nbsp;&nbsp;&nbsp; <font size=\"3\"> 一个优秀的 ML 模型，是要结合具体业务，从对数据流入的清洗，特征值维度的考量，模型类型的选择，到最终的性能的评估、监控、持续优化，都需要仔细地考究，最终才能打造出高效、稳定、精准的数据模型</font></p>\n<p><br></p>\n<h3 id=\"数据\">数据</h3>\n<p>&nbsp;&nbsp; <font size=\"2\"> 对目标数据集进行处理之前，首先就是对数据的类型进行归类，是数值型、类别型、文本型，还是其他一些多媒体、地理信息等<br>&nbsp;&nbsp; <font size=\"2\"> 针对不同的数据，分别采取不同的处理手段，对于类别型常用 1-of-k encoding 对每个类别进行编码<br>&nbsp;&nbsp; <font size=\"2\"> 对于文本型，则会采用 分词、移除 stop words (的、这、地; the/and/but …)、向量化、标准化 (避免度量单位的影响) like:</font></font></font></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div><div class=\"line\"></div><div class=\"line\">np.random.seed(<span class=\"number\">42</span>)</div><div class=\"line\">x = np.random.randn(<span class=\"number\">10</span>)</div><div class=\"line\">norm_x_2 = np.linalg.norm(x)</div><div class=\"line\">normalized_x = x / norm_x_2</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">\"x:\\n%s\"</span> % x</div><div class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">\"2-Norm of x: %2.4f\"</span> % norm_x_2</div><div class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">\"Normalized x:\\n%s\"</span> % normalized_x</div><div class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">\"2-Norm of normalized_x: %2.4f\"</span> % np.linalg.norm(normalized_x)</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> 还有还多常用的数据处理方式，如 平均值、中位数、总和、方差、差值、最大值、最小值<br>&nbsp;&nbsp; <font size=\"2\"> 对 time 的处理的方式，还有可以加上 “时间戳”</font></font></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">assign_tod</span><span class=\"params\">(hr)</span>:</span></div><div class=\"line\">   \ttimes_of_day = {</div><div class=\"line\">       \t<span class=\"string\">'morning'</span> : range(<span class=\"number\">7</span>, <span class=\"number\">12</span>),</div><div class=\"line\">       \t<span class=\"string\">'lunch'</span> : range(<span class=\"number\">12</span>, <span class=\"number\">14</span>),</div><div class=\"line\">       \t<span class=\"string\">'afternoon'</span> : range(<span class=\"number\">14</span>, <span class=\"number\">18</span>),</div><div class=\"line\">       \t<span class=\"string\">'evening'</span> : range(<span class=\"number\">18</span>, <span class=\"number\">23</span>),</div><div class=\"line\">       \t<span class=\"string\">'night'</span> : range(<span class=\"number\">23</span>, <span class=\"number\">7</span>)</div><div class=\"line\">   \t}</div><div class=\"line\">   \t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> times_of_day.iteritems():</div><div class=\"line\">   \t<span class=\"keyword\">if</span> hr <span class=\"keyword\">in</span> v:</div><div class=\"line\">\t    <span class=\"keyword\">return</span> k</div><div class=\"line\"></div><div class=\"line\">time_of_day = hour_of_day.map(<span class=\"keyword\">lambda</span> hr: assign_tod(hr))</div></pre></td></tr></table></figure>\n\n<p><br></p>\n<h3 id=\"特征维度\">特征维度</h3>\n<p>&nbsp;&nbsp; <font size=\"2\"> 常见的一个影响模型的因素，便是没有对特征 进行标准化</font></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">(element-wise - the preceding mean vector from the feature vector) / the vector of feature standard deviations</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> 利用 StandarScaler 完成标准化工作</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.mllib.feature.StandardScaler</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">val</span> scaler = <span class=\"keyword\">new</span> StandardScaler(withMean = <span class=\"keyword\">true</span>, withStd = <span class=\"keyword\">true</span>).fit(vectors)</div><div class=\"line\"><span class=\"keyword\">val</span> scaledData = data.map(lp =&gt; LabeledPoint(lp.label, scaler.transform(lp.features)))</div></pre></td></tr></table></figure>\n\n<p><br></p>\n<h3 id=\"调整模型\">调整模型</h3>\n<p>&nbsp;&nbsp; <font size=\"2\"> 首先需要在众多的模型 和 对应的算法 中找到最为适用的选择<br>&nbsp;&nbsp; <font size=\"2\"> 模型的类别主要有，推荐引擎、分类模型、回归模型、聚类模型 等<br>&nbsp;&nbsp; <font size=\"2\"> 相应的实现算法，又有（线性/逻辑/多元）回归、（随机森林）决策树、（朴素/高斯/多项式/伯努利/信念网络）贝叶斯 等<br>&nbsp;&nbsp; <font size=\"2\"> 在选择的时候，更多会考虑 特征值是否多维（可以尝试降维），目标类别是 multiclass，binary，还是 probability（连续值）</font></font></font></font></p>\n<p>&nbsp;&nbsp; <font size=\"2\"> 根据 数据集的 稀疏程度 对正则化 (Regularizer) 进行调整:</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">zero: 没有任何正规化操作</div><div class=\"line\">L1:   SGD（Stochastic gradient descent，随机梯度下降）</div><div class=\"line\">L2:   LBFGS（Limited-memory BFGS，受限的 BFGS）</div><div class=\"line\"></div><div class=\"line\">L2 相比 L1 更为平滑（同样，L1 可以让 稀疏的数据集 得到更 直观的模型）</div><div class=\"line\"></div><div class=\"line\">还有求最优解的方法，如 求全局最优解的 BGD（Batch gradient descent，批量梯度下降）</div><div class=\"line\">但是，由于每次迭代都需要依据训练集中所有的数据，所以速度很慢；</div><div class=\"line\">以及 CG（Conjugate gradient，共轭梯度法），其还没有被 Spark MLlib 支持，可以在 Breeze 中找到</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> 可以通过 setUpdater 将模型的 规则化算法 设置为 L1（默认为 L2）</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.mllib.optimization.L1Updater</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">val</span> svmAlg = <span class=\"keyword\">new</span> SVMWithSGD()</div><div class=\"line\">svmAlg.optimizer.</div><div class=\"line\">  setNumIterations(<span class=\"number\">200</span>).</div><div class=\"line\">  setRegParam(<span class=\"number\">0.1</span>).</div><div class=\"line\">  setUpdater(<span class=\"keyword\">new</span> L1Updater)</div><div class=\"line\"><span class=\"keyword\">val</span> modelL1 = svmAlg.run(training)</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> 当然，还有举不胜举的优化方式 sorry for the limit of article’s lenght :-)</font></p>\n<p><br></p>\n<h3 id=\"性能评估指标\">性能评估指标</h3>\n<p>&nbsp;&nbsp; <font size=\"2\"> I. 针对不同业务对性能评测的手段，也需要相应取舍，毕竟有些 霸道的防护系统，宁可错杀一千，就需要对 recall 有较高的要求，而 precision 则相对宽松些<br>&nbsp;&nbsp; <font size=\"2\"> 这是便可采用 ROC（receiver operating characteristic）curve 评测引擎:</font></font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// binary classification</span></div><div class=\"line\"><span class=\"keyword\">val</span> metrics = Seq(lrModel, svmModel).map { model =&gt;</div><div class=\"line\">  <span class=\"keyword\">val</span> scoreAndLabels = data.map { point =&gt;</div><div class=\"line\">    (model.predict(point.features), point.label)</div><div class=\"line\">  }</div><div class=\"line\">  <span class=\"keyword\">val</span> metrics = <span class=\"keyword\">new</span> BinaryClassificationMetrics(scoreAndLabels)</div><div class=\"line\">  (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> 如果是 贝叶斯/决策树 的数据模型，则可以用 0.5 对其进行划分，转换为 binary</font></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// naive bayes</span></div><div class=\"line\"><span class=\"keyword\">val</span> nbMetrics = Seq(nbModel).map { model =&gt;</div><div class=\"line\">  <span class=\"keyword\">val</span> scoreAndLabels = nbData.map { point =&gt;</div><div class=\"line\">    <span class=\"keyword\">val</span> score = model.predict(point.features)</div><div class=\"line\">    (<span class=\"keyword\">if</span> (score &gt; <span class=\"number\">0.5</span>) <span class=\"number\">1.0</span> <span class=\"keyword\">else</span> <span class=\"number\">0.0</span>, point.label)</div><div class=\"line\">  }</div><div class=\"line\">  <span class=\"keyword\">val</span> metrics = <span class=\"keyword\">new</span> BinaryClassificationMetrics(scoreAndLabels)</div><div class=\"line\">  (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)</div><div class=\"line\">}</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// decision tree</span></div><div class=\"line\"><span class=\"keyword\">val</span> dtMetrics = Seq(dtModel).map { model =&gt;</div><div class=\"line\">  <span class=\"keyword\">val</span> scoreAndLabels = data.map { point =&gt;</div><div class=\"line\">    <span class=\"keyword\">val</span> score = model.predict(point.features)</div><div class=\"line\">    (<span class=\"keyword\">if</span> (score &gt; <span class=\"number\">0.5</span>) <span class=\"number\">1.0</span> <span class=\"keyword\">else</span> <span class=\"number\">0.0</span>, point.label)</div><div class=\"line\">  }</div><div class=\"line\">  <span class=\"keyword\">val</span> metrics = <span class=\"keyword\">new</span> BinaryClassificationMetrics(scoreAndLabels)</div><div class=\"line\">  (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)</div><div class=\"line\">}</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">val</span> allMetrics = metrics ++ nbMetrics ++ dtMetrics</div><div class=\"line\">allMetrics.foreach { <span class=\"keyword\">case</span> (m, pr, roc) =&gt;</div><div class=\"line\">  println(f<span class=\"string\">\"$m, Area under PR: ${pr * 100.0}%2.4f%%, Area under ROC: ${roc * 100.0}%2.4f%%\"</span>)</div><div class=\"line\">}</div></pre></td></tr></table></figure>\n\n<p>&nbsp;&nbsp; <font size=\"2\"> II. 然而，如果是一些推荐系统，更多的希望能够了解到 大体的预测精度，则可以采用 MAP（Mean Average Precision） 平均精度均值 进行评估</font></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MAP 同时还解决了 precision，recall，F-measure 的单点值局限性</div></pre></td></tr></table></figure>\n\n<p><br></p>\n<p><strong><font size=\"2\"> <em>至此，相信你已经对 Spark 这个生态圈有了大致轮廓了，下面就是一步一步地在 实践 和 深入学习中，体验大数据的乐趣啦</em></font></strong></p>\n<p><br></p>\n<p><img src=\"/../2015-8-13/storm.jpg\" alt=\"\"><br><img src=\"/../2015-8-13/Spark.png\" alt=\"\"></p>\n<h4 id=\"更多资源：QQ_group:_(Hadoop_253793003)\">更多资源：QQ group: (<font color=\"blue\">Hadoop 253793003</font>)</h4>\n","source":"_posts/Real-time-ML-with-Spark.md","raw":"title: Real-time ML with Spark\ndate: 2015-08-13 19:50:21\ntags:\n - Spark\n - ML\ncategories:\n - Spark\n---\n\n\n## __<font color='blue'>*什么是 Spark?*__\n\n&nbsp;&nbsp; <font size=3> Apache Spark™ is a fast and general engine for large-scale data processing. - - [Official website][1]\n\n<br/>\n\n## __<font color='blue'>*为什么要有 Spark?*__\n###分布式\n```scala\n\t具备经济、快速、可靠、易扩充、数据共享、设备共享、通讯方便、灵活等分布式所具备的特性\n```\n\n###高层次抽象\n```scala\n\tRDD (Resilient Distributed Datasets) 提供 一个可以被并行计算的 不变、分区的数据集 抽象\n```\n\n###快速计算能力\n```scala\n\t内存计算 基于内存的迭代计算框架，能够避免计算结果落地，磁盘 I/O 所带来的瓶颈\n\tMachine Learning、Data mining 等多需要递归地计算，因此非常适合实现这些算法\n```\n\n###高效性能\n```scala\n\tDAG (Directed Acyclic Grap) 利用有向无环图，构建优化任务中 父 RDD 和 子 RDD 的依赖关系  (Like Ooize)\n\t依赖分为两种，一个为窄依赖，如 map/filter/union 等；另一种为宽依赖，如 groupByKey 等\n\t在划分依赖时，join 需要额外考虑 \"co-partitioner\"：\n\t    1. 如果 RDD 和 cogroup 有相同的 数据结构，将会确定一个 OneToOneDependency\n\t    2. 反之，则说明 join 的时候，需要 shuffle (ShuffleDependency)\n\t[建议]:\"wide dependencies 只有等到所有 父 partiton 计算完，并传递结束，才能继续进行下一步运算，所以应尽量减少宽依赖，避免失败后 recompute 的成本\"\n```\n\n###容错性\n```scala\n\tlineage 血统，能在计算失败的时候，将会找寻 最小重新计算损耗的 结点，而不是全部重复计算\n```\n\n<br/>\n\n## __<font color='blue'>*Spark 核心组件*__\n###Spark SQL\n```scala\n\t同时支持 HiveQL/UDFs/SerDes 等多样性的数据源，并采用 JDBC/ODBC 等标准化连接驱动，保证其通用性\n```\n\n###Spark GrapX\n```scala\n\t支持在 graph 或 collection 中查看数据，并提供丰富的 图形处理 API\n```\n\n###Spark Streaming\n```scala\n\t将数据流 按 时间间隔 Duration 划分为一组连续的 RDD，这些 RDD 抽象为 DStream\n\t随后，通过对 DStream 这个 high-level 抽象的操作，实现对底层 标记了 时间间隙 的 RDD 组的操控\n```\n\n###Spark MLbase\n```scala\n\t提供了对 Machine Learning 的易用、高效的实现\n\t总体的结构，基于 Spark，自底向上分别是，MLlib/MLI/ML Optimizer。\n\t    1. MLlib 这一层，设计了 本地/分布式 的矩阵，对稀疏数据的支持，多模型的训练，提供了 计算模型 和 逻辑的 API\n\t    2. MLI 主要任务则是 提供 表针采集器 和 逻辑规则，并进一步对 高层次 ML 编程抽象成接口\n\t    3. ML Optimizer 则是通过自动构建 ML 的 pipe 管道路径实现 ML 优化器的作用。\n\t       同时，此优化器还解决了一个在 MLI 和 MLlib 中 表征采集器 和 ML 逻辑规则的搜索问题\n```\n\n<br/>\n\n## __<font color='blue'>*Spark 实时机器学习*__\n###什么是[机器学习][4]？\n```scala\n\tWikipedia 给出的定义是，一个计算机科学的子领域，由 模式识别 和 人工智能中的计算机学习理论 演变而来\n\t探索 结构化的、可学习的规则引擎，如何用来对数据 进行训练 和 预测\n```\n\n###什么又是 Real-time 机器学习呢？\n```scala\n\t一般性的 机器学习 的对象 是一堆 offline 的训练集，通过对这些数据的学习，来确立模型\n\t如果数据是快速变化的，这时就需要将 新数据 分配好权重，加入到目标训练集中；之后，将预测出来的结果，再次反馈到 数据模型中去\n```\n\n###Real-time 和 No Real-time 的本质区别在哪儿？\n```scala\n\t因为 实时模型 是动态更新的，实现算法上，比 非实时的 ML 需要考虑，如何避免依赖 将 新数据 和 旧数据 整合在一块再计算所带来的性能问题\n\t更多时候，长期积累的数据，是很难再做到全量计算 (Like 多项式贝叶斯 Multinomial naive bayes, 用于处理 dataset 过大，而内存不足的情况)\n```\n\n<br/>\n\n## __<font color='blue'>*利用 Spark 实现 Real-time ML*__\n###源数据流\n&nbsp;&nbsp; <font size=2> I.\t利用 java.util.Random 产生满足高斯分布的随机数据，再通过 [breeze][5] 放入到 vector 中，作为 特征值\n&nbsp;&nbsp; <font size=2> II.\t在 generateNoisyData 中，将这个 vector 做 inner product, 并加入一点噪声数据，作为 label\n```scala\n    val MaxEvents = 100\n    val NumFeatures = 100\n    val random = new Random()\n\n    def generateRandomArray(n: Int) = Array.tabulate(n)(_ => random.nextGaussian())\n\n    val w = new DenseVector(generateRandomArray(NumFeatures))\n    val intercept = random.nextGaussian() * 10\n\n    def generateNoisyData(n: Int) = {\n      (1 to n).map { i =>\n        val x = new DenseVector(generateRandomArray(NumFeatures))\n\n        // inner product\n        val y: Double = w.dot(x)\n        val noisy = y + intercept\n        (noisy, x)\n      }\n    }\n```\n&nbsp;&nbsp; <font size=2> III.\t通过 socket 将数据 发送到指定端口\n```scala\n    if (args.length != 2) {\n      System.err.println(\"Usage: <port> <millisecond>\")\n      System.exit(1)\n    }\n\n    val listener = new ServerSocket(args(0).toInt)\n\n    while (true) {\n      val socket = listener.accept()\n\n      new Thread() {\n\n        override def run = {\n\n          println(\"Got client connected from: \" + socket.getInetAddress)\n\n          val out = new PrintWriter(socket.getOutputStream(), true)\n          while (true) {\n            Thread.sleep(args(1).toLong)\n\n            val num = random.nextInt(MaxEvents)\n            val data = generateNoisyData(num)\n\n            data.foreach { case (y, x) =>\n              val xStr = x.data.mkString(\",\")\n              val content = s\"$y\\t$xStr\"\n\n              println(content)\n\n              out.write(content)\n              out.write(\"\\n\")\n            }\n          }\n          socket.close()\n        }\n      }.start()\n    }\n```\n\n<br/>\n\n###实时 Machine Learning 模型\n&nbsp;&nbsp; <font size=2> I.\t指定 spark-master/interval 等参数，创建 StreamingContext（此处可以利用 <font color='blue'>local\\[n\\]</font> 快速开发）\n```scala\n    if (args.length < 4) {\n      System.err.println(\"Usage: WindowCounter <master> <hostname> <port> <interval> \\n\" +\n        \"In local mode, <master> should be 'local[n]' with n > 1\")\n      System.exit(1)\n    }\n\n    val ssc = new StreamingContext(args(0), \"ML Analysis\", Seconds(args(3).toInt))\n```\n\n&nbsp;&nbsp; <font size=2> II.\t获取到发送过来的 源数据\n```scala\n\tval stream = ssc.socketTextStream(args(1), args(2).toInt, StorageLevel.MEMORY_ONLY_SER)\n```\n\n&nbsp;&nbsp; <font size=2> III.\t利用 DenseVector.zeros\\[Double\\] 创建全零的初始矩阵\n&nbsp;&nbsp; <font size=2> IV.\t使用 StreamingLinearRegressionWithSGD 创建 流式随机递归下降的线性回归 模型\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font size=2>\t目前 MLlib 只支持 Streaming ( KMeans / LinearRegression / LinearRegressionWithSGD ) in [Spark 1.4.1][6]\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font size=2>\tStreaming MLlib 和普通的 MLlib 没有本质上的区别，只是输入的训练集是 DStream，需要使用 foreachRDD/map 进行 训练/预测 \n```scala\n    val NumFeatures = 100\n    val zeroVector = DenseVector.zeros[Double](NumFeatures)\n    val model = new StreamingLinearRegressionWithSGD()\n      .setInitialWeights(Vectors.dense(zeroVector.data))\n      .setNumIterations(1)\n      .setStepSize(0.01)\n\n    val labeledStream = stream.map { event =>\n      val split = event.split(\"\\t\")\n      val y = split(0).toDouble\n      val features = split(1).split(\",\").map(_.toDouble)\n      LabeledPoint(label = y, features = Vectors.dense(features))\n    }\n```\n\n&nbsp;&nbsp; <font size=2> V.\t利用 模型 进行 train / predict\n```scala\n\tmodel.trainOn(labeledStream)\n\n    val predictAndTrue = labeledStream.transform { rdd =>\n      val latest = model.latestModel()\n      rdd.map { point =>\n        val predict = latest.predict(point.features)\n        (predict - point.label)\n      }\n    }\n```\n\n&nbsp;&nbsp; <font size=2> VI.\t通过 MSE（Mean Squared Error） 均方差 和 RMSE（Root Mean Squared Error） 均方根误差 对模型的性能进行评估  (这里也可以使用 RegressionMetrics 来实现)\n```scala\n    predictAndTrue.foreachRDD { (rdd, time) =>\n      val mse = rdd.map { case (err) => err * err }.mean()\n      val rmse = math.sqrt(mse)\n      println( s\"\"\"\n                  |-------------------------------------------\n                  |Time: $time\n          |-------------------------------------------\n                      \"\"\".stripMargin)\n      println(s\"MSE current batch: Model : $mse\")\n      println(s\"RMSE current batch: Model : $rmse\")\n      println(\"...\\n\")\n    }\n```\n\n&nbsp;&nbsp; <font size=2> VII.\t启动 Spark 上下文\n```scala\n    ssc.start()\n    ssc.awaitTermination()\n```\n\n<br/>\n\n## __<font color='blue'>*一劳永逸了？Not at all*__\n&nbsp;&nbsp;&nbsp;&nbsp; <font size=3> 一个优秀的 ML 模型，是要结合具体业务，从对数据流入的清洗，特征值维度的考量，模型类型的选择，到最终的性能的评估、监控、持续优化，都需要仔细地考究，最终才能打造出高效、稳定、精准的数据模型\n\n<br/>\n\n###数据\n\n&nbsp;&nbsp; <font size=2> 对目标数据集进行处理之前，首先就是对数据的类型进行归类，是数值型、类别型、文本型，还是其他一些多媒体、地理信息等\n&nbsp;&nbsp; <font size=2> 针对不同的数据，分别采取不同的处理手段，对于类别型常用 1-of-k encoding 对每个类别进行编码\n&nbsp;&nbsp; <font size=2> 对于文本型，则会采用 分词、移除 stop words (的、这、地; the/and/but ...)、向量化、标准化 (避免度量单位的影响) like:\n\n\n```python\n\timport numpy as np\n\n\tnp.random.seed(42)\n\tx = np.random.randn(10)\n\tnorm_x_2 = np.linalg.norm(x)\n\tnormalized_x = x / norm_x_2\n\t\n\tprint \"x:\\n%s\" % x\n\tprint \"2-Norm of x: %2.4f\" % norm_x_2\n\tprint \"Normalized x:\\n%s\" % normalized_x\n\tprint \"2-Norm of normalized_x: %2.4f\" % np.linalg.norm(normalized_x)\n```\n\n&nbsp;&nbsp; <font size=2> 还有还多常用的数据处理方式，如 平均值、中位数、总和、方差、差值、最大值、最小值\n&nbsp;&nbsp; <font size=2> 对 time 的处理的方式，还有可以加上 \"时间戳\"\n\n```python\n\tdef assign_tod(hr):\n    \ttimes_of_day = {\n        \t'morning' : range(7, 12),\n        \t'lunch' : range(12, 14),\n        \t'afternoon' : range(14, 18),\n        \t'evening' : range(18, 23),\n        \t'night' : range(23, 7)\n    \t}\n    \tfor k, v in times_of_day.iteritems():\n    \tif hr in v:\n\t\t    return k\n\n\ttime_of_day = hour_of_day.map(lambda hr: assign_tod(hr))\n```\n\n<br/>\n\n###特征维度\n&nbsp;&nbsp; <font size=2> 常见的一个影响模型的因素，便是没有对特征 进行标准化\n```java\n\t(element-wise - the preceding mean vector from the feature vector) / the vector of feature standard deviations\n```\n&nbsp;&nbsp; <font size=2> 利用 StandarScaler 完成标准化工作\n```scala\n\timport org.apache.spark.mllib.feature.StandardScaler\n\n\tval scaler = new StandardScaler(withMean = true, withStd = true).fit(vectors)\n\tval scaledData = data.map(lp => LabeledPoint(lp.label, scaler.transform(lp.features)))\n```\n\n\n<br/>\n\n###调整模型\n\n&nbsp;&nbsp; <font size=2> 首先需要在众多的模型 和 对应的算法 中找到最为适用的选择\n&nbsp;&nbsp; <font size=2> 模型的类别主要有，推荐引擎、分类模型、回归模型、聚类模型 等\n&nbsp;&nbsp; <font size=2> 相应的实现算法，又有（线性/逻辑/多元）回归、（随机森林）决策树、（朴素/高斯/多项式/伯努利/信念网络）贝叶斯 等\n&nbsp;&nbsp; <font size=2> 在选择的时候，更多会考虑 特征值是否多维（可以尝试降维），目标类别是 multiclass，binary，还是 probability（连续值）\n\n&nbsp;&nbsp; <font size=2> 根据 数据集的 稀疏程度 对正则化 (Regularizer) 进行调整:\n```scala\n\tzero: 没有任何正规化操作\n\tL1:   SGD（Stochastic gradient descent，随机梯度下降）\n\tL2:   LBFGS（Limited-memory BFGS，受限的 BFGS）\n\t\n\tL2 相比 L1 更为平滑（同样，L1 可以让 稀疏的数据集 得到更 直观的模型）\n\t\n\t还有求最优解的方法，如 求全局最优解的 BGD（Batch gradient descent，批量梯度下降）\n\t但是，由于每次迭代都需要依据训练集中所有的数据，所以速度很慢；\n\t以及 CG（Conjugate gradient，共轭梯度法），其还没有被 Spark MLlib 支持，可以在 Breeze 中找到\n```\n\n&nbsp;&nbsp; <font size=2> 可以通过 setUpdater 将模型的 规则化算法 设置为 L1（默认为 L2）\n```scala\n\timport org.apache.spark.mllib.optimization.L1Updater\n\n\tval svmAlg = new SVMWithSGD()\n\tsvmAlg.optimizer.\n\t  setNumIterations(200).\n\t  setRegParam(0.1).\n\t  setUpdater(new L1Updater)\n\tval modelL1 = svmAlg.run(training)\n```\n\n&nbsp;&nbsp; <font size=2> 当然，还有举不胜举的优化方式 sorry for the limit of article's lenght :-)\n\n<br/>\n\n\n###性能评估指标\n\n&nbsp;&nbsp; <font size=2> I. 针对不同业务对性能评测的手段，也需要相应取舍，毕竟有些 霸道的防护系统，宁可错杀一千，就需要对 recall 有较高的要求，而 precision 则相对宽松些\n&nbsp;&nbsp; <font size=2> 这是便可采用 ROC（receiver operating characteristic）curve 评测引擎:\n```scala\n\t// binary classification\n\tval metrics = Seq(lrModel, svmModel).map { model =>\n\t  val scoreAndLabels = data.map { point =>\n\t    (model.predict(point.features), point.label)\n\t  }\n\t  val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n\t  (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)\n\t}\n```\n\n&nbsp;&nbsp; <font size=2> 如果是 贝叶斯/决策树 的数据模型，则可以用 0.5 对其进行划分，转换为 binary\n```scala\n\t// naive bayes\n\tval nbMetrics = Seq(nbModel).map { model =>\n\t  val scoreAndLabels = nbData.map { point =>\n\t    val score = model.predict(point.features)\n\t    (if (score > 0.5) 1.0 else 0.0, point.label)\n\t  }\n\t  val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n\t  (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)\n\t}\n\t\n\t// decision tree\n\tval dtMetrics = Seq(dtModel).map { model =>\n\t  val scoreAndLabels = data.map { point =>\n\t    val score = model.predict(point.features)\n\t    (if (score > 0.5) 1.0 else 0.0, point.label)\n\t  }\n\t  val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n\t  (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)\n\t}\n\t\n\tval allMetrics = metrics ++ nbMetrics ++ dtMetrics\n\tallMetrics.foreach { case (m, pr, roc) =>\n\t  println(f\"$m, Area under PR: ${pr * 100.0}%2.4f%%, Area under ROC: ${roc * 100.0}%2.4f%%\")\n\t}\n```\n\n&nbsp;&nbsp; <font size=2> II. 然而，如果是一些推荐系统，更多的希望能够了解到 大体的预测精度，则可以采用 MAP（Mean Average Precision） 平均精度均值 进行评估\n```java\n\tMAP 同时还解决了 precision，recall，F-measure 的单点值局限性\n```\n\n<br/>\n\n__<font size=2> *至此，相信你已经对 Spark 这个生态圈有了大致轮廓了，下面就是一步一步地在 实践 和 深入学习中，体验大数据的乐趣啦*__\n\n<br/>\n\n![][3]\n![][2]\n\n\n#### 更多资源：QQ group: (<font color='blue'>Hadoop 253793003</font>)\n\n\n[1]:http://spark.apache.org/\n[2]:/../2015-8-13/Spark.png\n[3]:/../2015-8-13/storm.jpg\n[4]:https://en.wikipedia.org/wiki/Machine_learning\n[5]:http://www.scalanlp.org/\n[6]:https://github.com/apache/spark/\n","slug":"Real-time-ML-with-Spark","updated":1439531365000,"excerpt":"","_id":"fhowbkkc6xchvbmo","comments":true,"layout":"post","photos":[],"link":""}],"Tag":[{"name":"Hadoop","_id":"a1l3pj63cwx79a5o","posts":["k67davxhfm4cdjf9"]},{"name":"RPC","_id":"3n9vfu5rcnuremwq","posts":["k67davxhfm4cdjf9"]},{"name":"Node.js","_id":"bqus80m5xcxzaorh","posts":["v5tsu8wyv17axfu8","s9x4sgxklpdb0w6t","lzq1z1qvh0t5lofq","2jri9d9jo6z7stv1"]},{"name":"Module","_id":"j6nschagr2jrxlwa","posts":["v5tsu8wyv17axfu8"]},{"name":"Python","_id":"fi8l4hi69ijj68zv","posts":["8asqaq0ueugeyyol"]},{"name":"Qcon","_id":"50ciaur9vavdib6s","posts":["iddp8bje6jh1iem0"]},{"name":"猿题库","_id":"e1tjoskwhawonzzl","posts":["iddp8bje6jh1iem0"]},{"name":"SSO","_id":"8vx42s7rnc3dvd7k","posts":["olrtd7b14rhsopss","e62ebblg305ndghv"]},{"name":"Session","_id":"3i102onxaw6lk3mf","posts":["olrtd7b14rhsopss","e62ebblg305ndghv"]},{"name":"Cookie","_id":"xcnxrp14cozuu482","posts":["olrtd7b14rhsopss"]},{"name":"Java","_id":"lg5ujhq2pmtkmi0y","posts":["e62ebblg305ndghv"]},{"name":"PHP","_id":"438n5ijdoh4276rx","posts":["e62ebblg305ndghv"]},{"name":"JSP","_id":"2mrmj7hdj23lrf8v","posts":["e62ebblg305ndghv"]},{"name":"Hibernate","_id":"5nl39kev5x2rq69n","posts":["e62ebblg305ndghv"]},{"name":"WebLogic","_id":"fnxfe9uy8e6qhde0","posts":["e62ebblg305ndghv"]},{"name":"HTTP","_id":"o22325zmryeb14yf","posts":["e62ebblg305ndghv"]},{"name":"Storm","_id":"jhce84bmw2q9nu7n","posts":["keg97xozltugcohs","9zrz1hse4e1drwhv","lz5zae3p0ex7sg0i"]},{"name":"Kafka","_id":"11cpxxkwjnfgt7bl","posts":["keg97xozltugcohs","9zrz1hse4e1drwhv","lz5zae3p0ex7sg0i"]},{"name":"Hexo","_id":"mut4rilgbnsjqb8w","posts":["3ngs3hwwgl0vbull"]},{"name":"JavaScript","_id":"4zpt0iwnywnmec6s","posts":["lzq1z1qvh0t5lofq"]},{"name":"JSON","_id":"7pj61lmo7g34jrwm","posts":["lzq1z1qvh0t5lofq"]},{"name":"NOSQL","_id":"42trimtt5i9u08s5","posts":["lzq1z1qvh0t5lofq"]},{"name":"ECMAScirpt","_id":"ex2eqjipdeq9k9ys","posts":["lzq1z1qvh0t5lofq"]},{"name":"V8","_id":"1b2g27f5ujb6fr6e","posts":["lzq1z1qvh0t5lofq"]},{"name":"Clojure","_id":"un8oejz6uj4bd78d","posts":["lzq1z1qvh0t5lofq"]},{"name":"ClojureScript","_id":"yrpxq03flc7lvilg","posts":["lzq1z1qvh0t5lofq"]},{"name":"HashMap","_id":"kt41z32ienkpakht","posts":["8d8a2twu1xotrk7c"]},{"name":"Hash","_id":"5f6v0je6qudesw6s","posts":["8d8a2twu1xotrk7c"]},{"name":"ConcurrentHashMap","_id":"z9aixi8437i6grje","posts":["8d8a2twu1xotrk7c"]},{"name":"Year_2038_problem","_id":"baw29kp8rfitqhbs","posts":["3cdgmchgzaj82c9h"]},{"name":"Antlr","_id":"1de012ov3n4zps8v","posts":["rmw8s9n3g5m99v69"]},{"name":"Spark","_id":"oi61cro9f77gtvjd","posts":["fhowbkkc6xchvbmo"]},{"name":"ML","_id":"bv1x3obr9dfbv4h4","posts":["fhowbkkc6xchvbmo"]}]}